<!DOCTYPE html>
<!--
   To publish this document, see instructions in README
   -->

<html lang="en-us" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us">
<head>
  <link href="getusermedia.css" rel="stylesheet" type="text/css" />

  <title>Media Capture and Streams</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
  <script class="remove" src="http://www.w3.org/Tools/respec/respec-w3c-common"
  type="text/javascript">
//<![CDATA[
  <!-- keep this comment -->
  //]]>
  </script>
  <script class="remove" src="getusermedia.js" type="text/javascript">
//<![CDATA[
  <!-- keep this comment -->
  //]]>
  </script>
</head>

<body>
  <section id="abstract">
    <p>This document defines a set of JavaScript APIs that allow local media,
    including audio and video, to be requested from a platform.</p>
  </section>


  <section id="sotd">
    <p>This document is not complete. It is subject to major changes and, while
    early experimentations are encouraged, it is therefore not intended for
    implementation. The API is based on preliminary work done in the
    WHATWG.</p>
  </section>


  <section class="informative" id="intro">
    <h2>Introduction</h2>


    <p>Access to multimedia streams (video, audio, or both) from local devices
    (video cameras, microphones, Web cams) can have a number of uses, such as
    real-time communication, recording, and surveillance.</p>


    <p>This document defines the APIs used to get access to local devices that
    can generate multimedia stream data. This document also defines the
    MediaStream API by which JavaScript is able to manipulate the stream data
    or otherwise process it.</p>
  </section>


  <section id="conformance">
    <p>This specification defines conformance criteria that apply to a single
    product: the <dfn>user agent</dfn> that implements the interfaces that it
    contains.</p>


    <p>Implementations that use ECMAScript to implement the APIs defined in
    this specification must implement them in a manner consistent with the
    ECMAScript Bindings defined in the Web IDL specification [[!WEBIDL]], as
    this specification uses that specification and terminology.</p>
  </section>


  <section>
    <h2>Terminology</h2>


    <dl>
      <dt><i>HTML Terms:</i>
      </dt>


      <dd>
        <p>The <code><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#eventhandler">EventHandler</a></code>
        interface represents a callback used for event handlers as defined in
        [[!HTML5]].</p>


        <p>The concepts <dfn><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#queue-a-task">queue a
        task</a></dfn> and <dfn><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#fire-a-simple-event">fires
        a simple event</a></dfn> are defined in [[!HTML5]].</p>


        <p>The terms <dfn><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#event-handlers">event
        handlers</a></dfn> and <dfn><a href=
        "http://dev.w3.org/html5/spec/webappapis.html#event-handler-event-type">
        event handler event types</a></dfn> are defined in [[!HTML5]].</p>
      </dd>


      <dt><dfn>source</dfn>
      </dt>


      <dd>
        <p>A source is the "thing" providing the source of a media stream
        track. The source is the broadcaster of the media itself. A source can
        be a physical webcam, microphone, local video or audio file from the
        user's hard drive, network resource, or static image.</p>


        <p>Some sources have an identifier which <em title="must" class=
        "rfc2119">must</em> be unique to the application (un-guessable by
        another application) and persistent between application sessions (e.g.,
        the identifier for a given source device/application must stay the
        same, but not be guessable by another application). Sources that must
        have an identifier are camera and microphone sources; local file
        sources are not required to have an identifier. Source identifiers let
        the application save, identify the availability of, and directly
        request specific sources.</p>


        <p>Other than the identifier, other bits of source identity are
        <strong>never</strong> directly available to the application until the
        user agent connects a source to a track. Once a source has been
        "released" to the application (either via a permissions UI,
        pre-configured allow-list, or some other release mechanism) the
        application will be able discover additional source-specific
        capabilities.</p>


        <p>Sources <strong>do not</strong> have constraints -- tracks have
        constraints. When a source is connected to a track, it must conform to
        the constraints present on that track (or set of tracks).</p>


        <p>Sources will be released (un-attached) from a track when the track
        is ended for any reason.</p>


        <p>On the <code><a>MediaStreamTrack</a></code> object, sources are
        represented by a <code><a>sourceType</a></code> attribute. The behavior
        of APIs associated with the source's capabilities and settings change
        depending on the source type.</p>


        <p>Sources have <code><a>capabilities</a></code> and
        <code><a>settings</a></code>. The capabilities and settings are "owned"
        by the source and are common to any (multiple) tracks that happen to be
        using the same source (e.g., if two different track objects bound to
        the same source ask for the same capability or setting information,
        they will get back the same answer).</p>
      </dd>


      <dt>
        <a>Setting</a> (Source Setting)
      </dt>


      <dd>
        <p>A setting refers to the immediate, current value of the source's
        (optionally constrained) capabilities. Settings are always
        read-only.</p>


        <p>A source's settings can change dynamically over time due to
        environmental conditions, sink configurations, or constraint changes. A
        source's settings must always conform to the current set of mandatory
        constraints that all of the tracks it is bound to have defined, and
        should do its best to conform to the set of optional constraints
        specified.</p>


        <p>A source's settings are directly exposed to audio and video track
        objects through individual read-only attributes. These attributes share
        the same name as their corresponding <a>capabilities</a> and
        <a>constraints</a>.</p>


        <p>Events are available that signal to the application that a source's
        settings have changed.</p>


        <p>A conforming user-agent <em title="must" class="rfc2119">must</em>
        support all the setting names defined in this spec.</p>
      </dd>


      <dt>
        <a>Capabilities</a>
      </dt>


      <dd>
        <p>Source capabilities are the intrinsic "features" of a source object.
        For each source setting, there is a corresponding capability that
        describes whether it is supported by the source and if so, what the
        range of supported values are. Capabilities are expressed as either a
        series of settings (for enumerated-type capabilities) or as a min/max
        range.</p>


        <p>The values of the supported capabilities must be normalized to the
        ranges and enumerated types defined in this specification.</p>


        <p>Capabilities return the same underlying per-source capabilities,
        regardless of any user-supplied constraints present on the source
        (capabilities are independent of constraints).</p>


        <p>Source capabilities are effectively constant. Applications should be
        able to depend on a specific source having the same capabilities for
        any session.</p>
      </dd>


      <dt>
        <a>Constraints</a>
      </dt>


      <dd>
        <p>Constraints are an optional feature for restricting the range of
        allowed variability on a source. Without provided constraints,
        implementations are free to select a source's settings from the full
        ranges of its supported capabilities, and to adjust those settings at
        any time for any reason.</p>


        <p>Constraints may be optional or mandatory. Optional constraints are
        represented by an ordered list, mandatory constraints are an unordered
        set. The order of the optional constraints is from most important (at
        the head of the list) to least important (at the tail of the list).</p>


        <p>Constraints are stored on the track object, not the source. Each
        track can be optionally initialized with constraints, or constraints
        can be added afterward through the constraint APIs defined in this
        spec.</p>


        <p>Applying track level constraints to a source is conditional based on
        the type of source. For example, read-only sources will ignore any
        specified constraints on the track.</p>


        <p>It is possible for two tracks that share a unique source to apply
        contradictory constraints. Under such contradictions, the
        implementation will mute both tracks and notify them that they are
        over-constrained.</p>


        <p>Events are available that allow the application to know when
        constraints cannot be met by the user agent. These typically occur when
        the application applies constraints beyond the capability of a source,
        contradictory constraints, or in some cases when a source cannot
        sustain itself in over-constrained scenarios (overheating, etc.).</p>


        <p>A correspondingly-named constraint exists for each corresponding
        source setting name and capability name. In general, user agents will
        have more flexibility to optimize the media streaming experience the
        fewer constraints are applied.</p>
      </dd>


      <dt><code>RTCPeerConnection</code>
      </dt>


      <dd><dfn><code>RTCPeerConnection</code></dfn> is defined in
      [[!WEBRTC10]].</dd>
    </dl>
  </section>


  <section id="stream-api">
    <h2>MediaStream API</h2>


    <section>
      <h2>Introduction</h2>


      <p>The <code><a>MediaStream</a></code> interface is used to represent
      streams of media data, typically (but not necessarily) of audio and/or
      video content, e.g. from a local camera. The data from a
      <code><a>MediaStream</a></code> object does not necessarily have a
      canonical binary form; for example, it could just be "the video currently
      coming from the user's video camera". This allows user agents to
      manipulate media streams in whatever fashion is most suitable on the
      user's platform.</p>


      <p>Each <code><a>MediaStream</a></code> object can contain zero or more
      tracks, in particular audio and video tracks. All tracks in a MediaStream
      are intended to be synchronized when rendered. Different MediaStreams do
      not need to be synchronized.</p>


      <p>Each track in a MediaStream object has a corresponding
      <code><a>MediaStreamTrack</a></code> object.</p>


      <p>A <code><a>MediaStreamTrack</a></code> represents content comprising
      one or more channels, where the channels have a defined well known
      relationship to each other (such as a stereo or 5.1 audio signal).</p>


      <p>A channel is the smallest unit considered in this API
      specification.</p>


      <p>A <code><a>MediaStream</a></code> object has an input and an output.
      The input depends on how the object was created: a
      <code><a>MediaStream</a></code> object generated by a <code><a href=
      "#dom-navigator-getusermedia">getUserMedia()</a></code> call (which is
      described later in this document), for instance, might take its input
      from the user's local camera. The output of the object controls how the
      object is used, e.g., what is saved if the object is written to a file or
      what is displayed if the object is used in a <code>video</code>
      element.</p>


      <p>Each track in a <code><a>MediaStream</a></code> object can be
      disabled, meaning that it is muted in the object's output. All tracks are
      initially enabled.</p>


      <p>A <code><a>MediaStream</a></code> can be <dfn><a>finished</a></dfn>,
      indicating that its inputs have forever stopped providing data.</p>


      <p>The output of a <code><a>MediaStream</a></code> object MUST correspond
      to the tracks in its input. Muted audio tracks MUST be replaced with
      silence. Muted video tracks MUST be replaced with blackness.</p>


      <p>A new <code><a>MediaStream</a></code> object can be created from
      accessible media sources (that does not require any additional
      permissions) using the <code><a href=
      "#dom-mediastream">MediaStream()</a></code> constructor. The constructor
      argument can either be an existing <code><a>MediaStream</a></code>
      object, in which case all the tracks of the given stream are added to the
      new <code><a>MediaStream</a></code> object, or an array of
      <code><a>MediaStreamTrack</a></code> objects. The latter form makes it
      possible to compose a stream from different source streams.</p>


      <p><img alt="A MediaStream" src="images/media-stream.png" width="418" />
      </p>


      <p>Both <code><a>MediaStream</a></code> and
      <code><a>MediaStreamTrack</a></code> objects can be cloned. This allows
      for greater control since the separate instances can be manipulated and
      <a title="consumer">consumed</a> individually. A cloned
      <code><a>MediaStream</a></code> contains clones of all member tracks from
      the original stream.</p>


      <p>When a <code><a>MediaStream</a></code> object is being generated from
      a local file (as opposed to a live audio/video source), the user agent
      SHOULD stream the data from the file in real time, not all at once. The
      <code>MediaStream</code> object is also used in contexts outside
      <code>getUserMedia</code>, such as [[!WEBRTC10]]. In both cases, ensuring
      a realtime stream reduces the ease with which pages can distinguish live
      video from pre-recorded video, which can help protect the user's
      privacy.</p>
    </section>


    <section>
      <h2>MediaStream</h2>


      <p>The <dfn id="dom-mediastream"><code>MediaStream()</code></dfn>
      constructor composes a new stream out of existing tracks. It takes an
      optional argument of type <code><a>MediaStream</a></code> or an array of
      <code><a>MediaStreamTrack</a></code> objects. <dfn id=
      'mediastream-constructor'>When the constructor is invoked</dfn>, the UA
      must run the following steps:</p>


      <ol>
        <li>
          <p>Let <var>stream</var> be a newly constructed
          <code><a>MediaStream</a></code> object.</p>
        </li>


        <li>
          <p>Initialize <var>stream's</var> <code><a href=
          "#dom-mediastream-id">id</a></code> attribute to a newly generated
          value.</p>
        </li>


        <li>
          <p>If the constructor's argument is present, run the sub steps that
          corresponds to the argument type.</p>


          <ul>
            <li>
              <p><code>Array</code> of <code><a>MediaStreamTrack</a></code>
              objects:</p>


              <p>Run the following sub steps for each
              <code><a>MediaStreamTrack</a></code> in the array:</p>


              <ol>
                <li>
                  <p><em>Add track</em>: Let <var>track</var> be the
                  <code><a>MediaStreamTrack</a></code> about to be
                  processed.</p>
                </li>


                <li>
                  <p>If <var>track</var> has <a href="#track-ended">ended</a>,
                  then abort these steps and continue with the next track (if
                  any).</p>
                </li>


                <li>
                  <p>Add <var>track</var> to <var>stream</var>'s <a href=
                  "#track-set">track set</a>.</p>
                </li>
              </ol>
            </li>


            <li>
              <p><code><a>MediaStream</a></code>:</p>


              <p>Run the sub steps labeled <em>Add track</em> (above) for every
              <code><a>MediaStreamTrack</a></code> in the argument stream's
              <a href="#track-set">track set</a>.</p>
            </li>
          </ul>
        </li>


        <li>
          <p>If <var>stream</var>'s <a href="#track-set">track set</a> is
          empty, set <var>stream</var>'s <code><a href=
          "#dom-mediastream-active">active</a></code> attribute to
          <code>false</code>, otherwise set it to <code>true</code>.</p>
        </li>


        <li>
          <p>Return <var>stream</var>.</p>
        </li>
      </ol>


      <p>A <code><a>MediaStream</a></code> can have multiple audio and video
      sources (e.g. because the user has multiple microphones, or because the
      real source of the stream is a media resource with many media tracks).
      The stream represented by a <code><a>MediaStream</a></code> thus has zero
      or more tracks.</p>


      <p>The tracks of a <code><a>MediaStream</a></code> are stored in a
      <dfn id="track-set">track set</dfn>. The track set MUST contain the
      <code><a>MediaStreamTrack</a></code> objects that correspond to the
      tracks of the stream. The relative order of the tracks in the set is user
      agent defined and the API will never put any requirements on the order.
      The proper way to find a specific <code><a>MediaStreamTrack</a></code>
      object in the set is to look it up by its <code><a href=
      "#dom-mediastreamtrack-id">id</a></code>.</p>


      <p>An object that reads data from the output of a
      <code><a>MediaStream</a></code> is referred to as a
      <code><a>MediaStream</a></code> <dfn>consumer</dfn>. The list of
      <code><a>MediaStream</a></code> consumers currently include the media
      elements [[HTML5]], <code>RTCPeerConnection</code> [[WEBRTC10]],
      <code>MediaRecorder</code> [[mediastream-rec]] and
      <code>ImageCapture</code> [[mediastream-imagecap]].</p>


      <p class="note"><code><a>MediaStream</a></code> consumers must be able to
      handle tracks being added and removed. This behavior is specified per
      consumer.</p>


      <p>A <code><a>MediaStream</a></code> object is said to be <dfn id=
      "stream-inactive">MediaStream.inactive</dfn> when it does not have any
      tracks or all tracks belonging to the stream have <a href=
      "#track-ended">ended</a>. Otherwise the stream is active. A
      <code><a>MediaStream</a></code> can start its life as inactive if it is
      constructed without any tracks.</p>


      <p>When a <code><a>MediaStream</a></code> goes from being active to
      inactive, the user agent MUST queue a task that sets the object's
      <code><a href="#dom-mediastream-active">active</a></code> attribute to
      <code>false</code> and fire a simple event named <code><a href=
      "#event-mediastream-inactive">inactive</a></code> at the object. When a
      <code><a>MediaStream</a></code> goes from being inactive to active, the
      user agent MUST queue a task that sets the object's <code><a href=
      "#dom-mediastream-active">active</a></code> attribute to
      <code>true</code> and fire a simple event named <code><a href=
      "#event-mediastream-active">active</a></code> at the object.</p>


      <p>If the stream's activity status changed due to a user request, the
      task source for this <span title="concept-task">task</span> is the user
      interaction task source. Otherwise the task source for this <span title=
      "concept-task">task</span> is the networking task source.</p>


      <dl class="idl" title="interface MediaStream : EventTarget">
        <dt>Constructor()</dt>


        <dd>
          See the <a href="#mediastream-constructor">MediaStream constructor
          algorithm</a>
        </dd>


        <dt>Constructor(MediaStream stream)</dt>


        <dd>
          See the <a href="#mediastream-constructor">MediaStream constructor
          algorithm</a>
        </dd>


        <dt>Constructor(sequence&lt;MediaStreamTrack&gt; tracks)</dt>


        <dd>
          See the <a href="#mediastream-constructor">MediaStream constructor
          algorithm</a>
        </dd>


        <dt>readonly attribute DOMString id</dt>


        <dd>
          <p>When a <code><a>MediaStream</a></code> object is created, the user
          agent MUST generate a globally unique identifier string, and MUST
          initialize the object's <code><a href=
          "#dom-mediastream-id">id</a></code> attribute to that string. Such
          strings MUST only use characters in the ranges U+0021, U+0023 to
          U+0027, U+002A to U+002B, U+002D to U+002E, U+0030 to U+0039, U+0041
          to U+005A, U+005E to U+007E, and MUST be 36 characters long.</p>
          <!-- UUIDs have 36 characters
      including hyphens; the ranges above comes from RFC4574 (the a=label:
      thing in SDP) -->
          <!-- described below -->


          <p>The <dfn id="dom-mediastream-id"><code>id</code></dfn> attribute
          MUST return the value to which it was initialized when the object was
          created.</p>
        </dd>


        <dt>sequence&lt;MediaStreamTrack&gt; getAudioTracks()</dt>


        <dd>
          <p>Returns a sequence of <code><a>MediaStreamTrack</a></code> objects
          representing the audio tracks in this stream.</p>


          <p>The <dfn id=
          "dom-mediastream-getaudiotracks"><code>getAudioTracks()</code></dfn>
          method MUST return a sequence that represents a snapshot of all the
          <code><a>MediaStreamTrack</a></code> objects in this stream's
          <a href="#track-set">track set</a> whose <code><a href=
          "#dom-mediastreamtrack-kind">kind</a></code> is equal to
          "<code>audio</code>". The conversion from the <a href=
          "#track-set">track set</a> to the sequence is user agent defined and
          the order does not have to stable between calls.</p>
        </dd>


        <dt>sequence&lt;MediaStreamTrack&gt; getVideoTracks()</dt>


        <dd>
          <p>Returns a sequence of <code><a>MediaStreamTrack</a></code> objects
          representing the video tracks in this stream.</p>


          <p>The <dfn id=
          "dom-mediastream-getvideotracks"><code>getVideoTracks()</code></dfn>
          method MUST return a sequence that represents a snapshot of all the
          <code><a>MediaStreamTrack</a></code> objects in this stream's
          <a href="#track-set">track set</a> whose <code><a href=
          "#dom-mediastreamtrack-kind">kind</a></code> is equal to
          "<code>video</code>". The conversion from the <a href=
          "#track-set">track set</a> to the sequence is user agent defined and
          the order does not have to stable between calls.</p>
        </dd>


        <dt>MediaStreamTrack? getTrackById(DOMString trackId)</dt>


        <dd>
          <p>The <dfn id=
          "dom-mediastream-gettrackbyid"><code>getTrackById()</code></dfn>
          method MUST return the first <code><a>MediaStreamTrack</a></code>
          object in this stream's <a href="#track-set">track set</a> whose
          <code><a href="#dom-mediastreamtrack-id">id</a></code> is equal to
          <var>trackId</var>. The method MUST return null if no track matches
          the <var>trackId</var> argument.</p>
        </dd>


        <dt>void addTrack(MediaStreamTrack track)</dt>


        <dd>
          <p>Adds the given <code><a>MediaStreamTrack</a></code> to this
          <code><a>MediaStream</a></code>.</p>


          <p>When the <dfn id=
          "dom-mediastream-addtrack"><code>addTrack()</code></dfn> method is
          invoked, the user agent MUST run the following steps:</p>


          <ol>
            <li>
              <p>Let <var>track</var> be the
              <code><a>MediaStreamTrack</a></code> argument and
              <var>stream</var> this <code><a>MediaStream</a></code>
              object.</p>
            </li>


            <li>
              <p>If <var>stream</var> is <a>finished</a>, throw an
              <code>INVALID_STATE_ERR</code> exception.</p>
            </li>


            <li>
              <p>If <var>track</var> is already in <var>stream's</var> <a href=
              "#track-set">track set</a>, then abort these steps.</p>
            </li>


            <li>
              <p>Add <var>track</var> to <var>stream</var>'s <a href=
              "#track-set">track set</a>.</p>
            </li>
          </ol>
        </dd>


        <dt>void removeTrack(MediaStreamTrack track)</dt>


        <dd>
          <p>Removes the given <code><a>MediaStreamTrack</a></code> from this
          <code><a>MediaStream</a></code>.</p>


          <p>When the <dfn id=
          "dom-mediastream-removetrack"><code>removeTrack()</code></dfn> method
          is invoked, the user agent MUST run the following steps:</p>


          <ol>
            <li>
              <p>Let <var>track</var> be the
              <code><a>MediaStreamTrack</a></code> argument and
              <var>stream</var> this <code><a>MediaStream</a></code>
              object.</p>
            </li>


            <li>
              <p>If <var>stream</var> is <a>finished</a>, throw an
              <code>INVALID_STATE_ERR</code> exception.</p>
            </li>


            <li>
              <p>If <var>track</var> is in <var>stream</var>'s <a href=
              "#track-set">track set</a>, remove it.</p>
            </li>
          </ol>
        </dd>


        <dt>MediaStream clone()</dt>


        <dd>
          <p>Clones the given <code><a>MediaStream</a></code> and all its
          tracks.</p>


          <p>When the <dfn id=
          "dom-mediastream-clone"><code>MediaStream.clone()</code></dfn> method
          is invoked, the user agent MUST run the following steps:</p>


          <ol>
            <li>
              <p>Let <var>streamClone</var> be a newly constructed
              <code><a>MediaStream</a></code> object.</p>
            </li>


            <li>
              <p>Initialize <var>streamClone</var>'s <code><a href=
              "#dom-mediastream-id">id</a></code> attribute to a newly
              generated value.</p>
            </li>


            <li>
              <p>Let <var>trackSetClone</var> be a list that contains the
              result of running <code><a href=
              "#dom-mediastreamtrack-clone">MediaStreamTrack.clone()</a></code>
              on all the tracks in this stream.</p>
            </li>


            <li>
              <p>Let <var>trackSetClone</var> be <var>streamClone</var>'s
              <a href="#track-set">track set</a>.</p>
            </li>
          </ol>
        </dd>


        <dt>readonly attribute boolean active</dt>


        <dd>
          <p>The <dfn id=
          "dom-mediastream-active"><code>MediaStream.active</code></dfn>
          attribute returns true if the <code><a>MediaStream</a></code> is
          active (see <a href="#stream-inactive">inactive</a>), and false
          otherwise.</p>


          <p>When a <code><a>MediaStream</a></code> object is created, its
          <code><a href="#dom-mediastream-active">active</a></code> attribute
          MUST be set to true, unless stated otherwise (for example by the
          <code><a href="#dom-mediastream">MediaStream()</a></code> constructor
          algorithm).</p>
        </dd>


        <dt>attribute EventHandler onactive</dt>


        <dd>This event handler, of type <code><a href=
        "#event-mediastream-active">active</a></code>, MUST be supported by all
        objects implementing the <code><a>MediaStream</a></code>
        interface.</dd>


        <dt>attribute EventHandler oninactive</dt>


        <dd>This event handler, of type <code><a href=
        "#event-mediastream-inactive">inactive</a></code>, MUST be supported by
        all objects implementing the <code><a>MediaStream</a></code>
        interface.</dd>


        <dt>attribute EventHandler onaddtrack</dt>


        <dd>This event handler, of type <code><a href=
        "#event-mediastream-addtrack">addtrack</a></code>, MUST be supported by
        all objects implementing the <code><a>MediaStream</a></code>
        interface.</dd>


        <dt>attribute EventHandler onremovetrack</dt>


        <dd>This event handler, of type <code><a href=
        "#event-mediastream-removetrack">removetrack</a></code>, MUST be
        supported by all objects implementing the
        <code><a>MediaStream</a></code> interface.</dd>
      </dl>
    </section>


    <section>
      <h2>MediaStreamTrack</h2>


      <p>A <code><a>MediaStreamTrack</a></code> object represents a media
      source in the user agent. Several <code><a>MediaStreamTrack</a></code>
      objects can represent the same media source, e.g., when the user chooses
      the same camera in the UI shown by two consecutive calls to
      <code><a href="#dom-navigator-getusermedia">getUserMedia()</a></code>
      .</p>


      <p>A script can indicate that a track no longer needs its source with the
      <code><a href=
      "#dom-mediastreamtrack-stop">MediaStreamTrack.stop()</a></code> method.
      When all tracks using a source have been stopped, the given permission
      for that source is revoked and the source is <dfn id=
      "source-stopped">stopped</dfn>. If the data is being generated from a
      live source (e.g., a microphone or camera), then the user agent SHOULD
      remove any active "on-air" indicator for that source. If the data is
      being generated from a prerecorded source (e.g. a video file), any
      remaining content in the file is ignored. An implementation may use a per
      source reference count to keep track of source usage, but the specifics
      are out of scope for this specification.</p>


      <section>
        <h3>Life-cycle and Media Flow</h3>


        <p>A <code><a>MediaStreamTrack</a></code> has three stages in its
        lifecycle; <code>new</code>, <code>live</code> and <code>ended</code>.
        A track begins as <code>new</code> prior to being connected to an
        active source.</p>


        <p>Once connected, the <code><a href=
        "#event-mediastreamtrack-started">started</a></code> event fires and
        the track becomes <code>live</code>. In the <code>live</code> state,
        the track is active and media is available for rendering at a
        <code><a>MediaStream</a></code> <a>consumer</a>.</p>


        <p>A muted or disabled <code><a>MediaStreamTrack</a></code> renders
        either silence (audio), black frames (video), or a
        zero-information-content equivalent. For example, a video element
        sourced by a muted or disabled <code><a>MediaStreamTrack</a></code>
        (contained within a <code><a>MediaStream</a></code>), is playing but
        the rendered content is the muted output.</p>


        <p>The muted/unmuted state of a track reflects if the source provides
        any media at this moment. The enabled/disabled state is under
        application control and determines if the track outputs media (to its
        consumers). Hence, media from the source only flows when a
        <code><a>MediaStreamTrack</a></code> object is both unmuted and
        enabled.</p>


        <p>A <code><a>MediaStreamTrack</a></code> is <dfn id=
        "track-muted">muted</dfn> when the source is temporarily unable to
        provide the track with data. A track can be muted by a user. Often this
        action is outside the control of the application. This could be as a
        result of the user hitting a hardware switch, or toggling a control in
        the operating system or browser chrome. A track can also be muted by
        the user agent. For example, a track that is a member of a
        <code><a>MediaStream</a></code>, received via a
        <code><a>RTCPeerConnection</a></code> [[!WEBRTC10]], is muted if the
        application on the other side disables the corresponding track in the
        <code>MediaStream</code> being sent.</p>


        <p>Applications are able to <dfn id="track-enabled">enable</dfn> or
        disable a <code><a>MediaStreamTrack</a></code> to prevent it from
        rendering media from the source. A muted track will however, regardless
        of the enabled state, render silence and blackness. A disabled track is
        logically equivalent to a muted track, from a consumer point of
        view.</p>


        <p>For a newly created <code><a>MediaStreamTrack</a></code> object, the
        following applies. The track is always enabled unless stated otherwise
        (for example when cloned) and the muted state reflects the state of the
        source at the time the track is created.</p>


        <p>A <code><a>MediaStreamTrack</a></code> object is said to
        <em>end</em> when the source of the track is disconnected or
        exhausted.</p>


        <p>When a <code><a>MediaStreamTrack</a></code> object ends for any
        reason (e.g., because the user rescinds the permission for the page to
        use the local camera, or because the data comes from a finite file and
        the file's end has been reached and the user has not requested that it
        be looped, or because the UA has instructed the track to end for any
        reason, it is said to be ended. When track instance <var>track</var>
        ends for any reason other than the <code><a href=
        "#dom-mediastreamtrack-stop">stop()</a></code> method being invoked on
        the <code><a>MediaStreamTrack</a></code> object that represents
        <var>track</var>, the user agent MUST queue a task that runs the
        following steps:</p>


        <ol>
          <li>
            <p>If the track's <code><a href=
            "#dom-mediastreamtrack-readystate">readyState</a></code> attribute
            has the value <code>ended</code> already, then abort these steps.
            (The <code><a href="#dom-mediastreamtrack-stop">stop()</a></code>
            method was probably called just before the track stopped for other
            reasons.)</p>
          </li>


          <li>
            <p>Set <var>track's</var> <code><a href=
            "#dom-mediastreamtrack-readystate">readyState</a></code> attribute
            to <code>ended</code>.</p>
          </li>


          <li>
            <p>Fire a simple event named <code><a href=
            "#event-mediastreamtrack-ended">ended</a></code> at the object.</p>
          </li>
        </ol>


        <p>If the end of the stream was reached due to a user request, the
        event source for this event is the user interaction event source.</p>
        <!-- TODO CULLEN NO IDEA WHY THIS NEEDED FIX -->
      </section>


      <section>
        <h3>Tracks and Constraints</h3>


        <p>Constraints are independent of sources. However, if the
        <code><a>sourceType</a></code> is "none", the
        <code><a>readonly</a></code> attribute is <code>true</code>, or the
        <code><a>remote</a></code> attribute is <code>true</code>, the track's
        constraints will not be applied to the source.</p>


        <p>Whether <code><a>Constraints</a></code> were provided at track
        initialization time or need to be established later at runtime, the
        APIs defined in the <a>Constrainable</a> Interface allow the retrieval
        and manipulation of the constraints currently established on a
        track.</p>


        <p>Each track maintains an internal version of the
        <code><a>Constraints</a></code> structure, namely a mandatory set of
        constraints (no duplicates), and an optional ordered list of individual
        constraint objects (may contain duplicates). The internal stored
        constraint structure is exposed to the application by the
        <code><a>constraints</a></code> attribute, and may be modified by the
        <code><a>applyConstraints()</a></code> method.</p>


        <p>When <code><a>applyConstraints()</a></code> is called, a user agent
        <em title="must" class="rfc2119">must</em> queue a task to evaluate
        those changes when the task queue is next serviced. Similarly, if the
        <a href=
        "#widl-MediaSourceStates-sourceType"><code>sourceType</code></a>
        changes, then the user agent should perform the same actions to
        re-evaluate the constraints of each track affected by that source
        change.</p>
      </section>


      <section>
        <h3>Interface Definition</h3>


        <div class="idl" title="MediaStreamTrack implements Constrainable">
        </div>


        <dl class="idl" title="interface MediaStreamTrack : EventTarget">
          <dt>readonly attribute DOMString kind</dt>


          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-kind"><code>MediaStreamTrack.kind</code></dfn>
            attribute MUST return the string "<code>audio</code>" if the object
            represents an audio track or "<code>video</code>" if object
            represents a video track.</p>
          </dd>


          <dt>readonly attribute DOMString id</dt>


          <dd>
            <p>Unless a <code><a>MediaStreamTrack</a></code> object is created
            as a part a of special purpose algorithm that specifies how the
            track id must be initialized, the user agent MUST generate a
            globally unique identifier string and initialize the object's
            <code><a href="#dom-mediastreamtrack-id">id</a></code> attribute to
            that string.</p>


            <p>An example of an algorithm that specifies how the track id must
            be initialized is the algorithm to represent an incoming network
            component with a <code><a>MediaStreamTrack</a></code> object.
            [[!WEBRTC10]]</p>


            <p><dfn id=
            "dom-mediastreamtrack-id"><code>MediaStreamTrack.id</code></dfn>
            attribute MUST return the value to which it was initialized when
            the object was created.</p>
          </dd>


          <dt>readonly attribute DOMString label</dt>


          <dd>
            <p>User agents MAY label audio and video sources (e.g., "Internal
            microphone" or "External USB Webcam"). The <dfn id=
            "dom-mediastreamtrack-label"><code>MediaStreamTrack.label</code></dfn>
            attribute MUST return the label of the object's corresponding
            track, if any. If the corresponding track has or had no label, the
            attribute MUST instead return the empty string.</p>


            <p class="note">Thus the <code><a href=
            "#dom-mediastreamtrack-kind">kind</a></code> and <code title=
            "dom-MediaStreamTrack-label"><a href=
            "#dom-mediastreamtrack-label">label</a></code> attributes do not
            change value, even if the <code><a>MediaStreamTrack</a></code>
            object is disassociated from its corresponding track.</p>
          </dd>


          <dt>attribute boolean enabled</dt>


          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-enabled"><code>MediaStreamTrack.enabled</code></dfn>
            attribute, on getting, MUST return the last value to which it was
            set. On setting, it MUST be set to the new value, and then, if the
            <code><a>MediaStreamTrack</a></code> object is still associated
            with a track, MUST enable the track if the new value is true, and
            disable it otherwise.</p>


            <p class="note">Thus, after a <code><a>MediaStreamTrack</a></code>
            is disassociated from its track, its <code><a href=
            "#dom-mediastreamtrack-enabled">enabled</a></code> attribute still
            changes value when set; it just doesn't do anything with that new
            value.</p>
          </dd>


          <dt>readonly attribute boolean muted</dt>


          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-muted"><code>MediaStreamTrack.muted</code></dfn>
            attribute MUST return <code>true</code> if the track is <a href=
            "#track-muted">muted</a>, and <code>false</code> otherwise.</p>
          </dd>


          <dt>attribute EventHandler onmute</dt>


          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-mute">mute</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>


          <dt>attribute EventHandler onunmute</dt>


          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-unmute">unmute</a></code>, MUST be supported
          by all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>


          <dt>readonly attribute boolean _readonly</dt>


          <dd>If the track (audio or video) is backed by a read-only source
          such as a file, or the track source is a local microphone or camera,
          but is shared so that constraints applied to the track cannot modify
          the source's state, the <dfn id=
          "dom-mediastreamtrack-readonly"><code>readonly</code></dfn> attribute
          MUST return the value <code>true</code>. Otherwise, it must return
          the value <code>false</code>.</dd>


          <dt>readonly attribute boolean remote</dt>


          <dd>If the track is sourced by an <code>RTCPeerConnection</code>, the
          <dfn id="dom-mediastreamtrack-remote"><code>remote</code></dfn>
          attribute MUST return the value <code>true</code>. Otherwise, it must
          return the value <code>false</code>.</dd>


          <dt>readonly attribute MediaStreamTrackState readyState</dt>


          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-readystate"><code>readyState</code></dfn>
            attribute represents the state of the track. It MUST return the
            value to which the user agent last set it.</p>
          </dd>


          <dt>attribute EventHandler onstarted</dt>


          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-started">started</a></code>, MUST be
          supported by all objects implementing the
          <code><a>MediaStreamTrack</a></code> interface.</dd>


          <dt>attribute EventHandler onended</dt>


          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-ended">ended</a></code>, MUST be supported
          by all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>


          <dt>MediaStreamTrack clone()</dt>


          <dd>
            <p>Clones the given <code><a>MediaStreamTrack</a></code>.</p>


            <p>When the <dfn id=
            "dom-mediastreamtrack-clone"><code>MediaStreamTrack.clone()</code></dfn>
            method is invoked, the user agent MUST run the following steps:</p>


            <ol>
              <li>
                <p>Let <var>trackClone</var> be a newly constructed
                <code><a>MediaStreamTrack</a></code> object.</p>
              </li>


              <li>
                <p>Initialize <var>trackClone</var>'s <code><a href=
                "#dom-mediastreamtrack-id">id</a></code> attribute to a newly
                generated value.</p>
              </li>


              <li>
                <p>Let <var>trackClone</var> inherit this track's underlying
                source, <code><a href=
                "#dom-mediastreamtrack-kind">kind</a></code>, <code><a href=
                "#dom-mediastreamtrack-label">label</a></code> and
                <code><a href=
                "#dom-mediastreamtrack-enabled">enabled</a></code>
                attributes.</p>
              </li>


              <li>
                <p>Return <var>trackClone</var>.</p>
              </li>
            </ol>
          </dd>


          <dt>void stop ()</dt>


          <dd>
            <p>When a <code><a>MediaStreamTrack</a></code> object's <dfn id=
            "dom-mediastreamtrack-stop"><code>stop()</code></dfn> method is
            invoked, the user agent MUST run following steps:</p>


            <ol>
              <li>
                <p>Let <var>track</var> be the current
                <code><a>MediaStreamTrack</a></code> object.</p>
              </li>


              <li>
                <p>If <var>track</var> has no source attached
                (<code><a>sourceType</a></code> is "none") or if the source is
                provided by an <code>RTCPeerConnection</code>, then abort these
                steps.</p>
              </li>


              <li>
                <p>Set <var>track's</var> <code><a href=
                "#dom-mediastreamtrack-readystate">readyState</a></code>
                attribute to <code>ended</code>.</p>
              </li>


              <li>
                <p>Detach <var>track's</var> source.</p>


                <p>If no other <code><a>MediaStreamTrack</a></code> is using
                the same source, the source will be <a href=
                "#source-stopped">stopped</a>.</p>
              </li>
            </ol>


            <p>The task source for the <span title="concept-task">tasks</span>
            queued for the <code><a href=
            "#dom-mediastreamtrack-stop">stop()</a></code> method is the DOM
            manipulation task source.</p>
          </dd>
        </dl>


        <dl class='idl' title='enum MediaStreamTrackState'>
          <dt>new</dt>


          <dd>The track type is new and has not been initialized (connected to
          a source of any kind). This state implies that the track's label will
          be the empty string.</dd>


          <dt>live</dt>


          <dd>
            <p>The track is active (the track's underlying media source is
            making a best-effort attempt to provide data in real time).</p>


            <p>The output of a track in the <code>live</code> state can be
            switched on and off with the <code><a href=
            "#dom-mediastreamtrack-enabled">enabled</a></code> attribute.</p>
          </dd>


          <dt>ended</dt>


          <dd>
            <p>The track has <a href="#track-ended">ended</a> (the track's
            underlying media source is no longer providing data, and will never
            provide more data for this track). Once a track enters this state,
            it never exits it.</p>


            <p>For example, a video track in a <code><a>MediaStream</a></code>
            ends if the user unplugs the USB web camera that acts as the
            track's media source.</p>
          </dd>
        </dl>
      </section>


      <section>
        <h2>Track Source Types</h2>


        <dl class="idl" title="enum SourceTypeEnum">
          <dt>none</dt>


          <dd>This track has no source. This is the case when the track is in
          the <code>"new"</code> or <code>"ended"</code>
          <code><a>readyState</a></code>.</dd>


          <dt>camera</dt>


          <dd>A valid source type only for
          <code><a>VideoStreamTrack</a></code>s. The source is a local
          video-producing camera source.</dd>


          <dt>microphone</dt>


          <dd>A valid source type only for
          <code><a>AudioStreamTrack</a></code>s. The source is a local
          audio-producing microphone source.</dd>
        </dl>
      </section>


      <section>
        <h2>Isolated Media Streams</h2>


        <p>When either of the "noaccess" or "peerIdentity" constraints is
        applied to a MediaStreamTrack, the track shall be isolated so that its
        content is not accessible to the content JS. An isolated media stream
        may be used for two purposes:</p>


        <ul>
          <li>
            <p>Displayed in an appropriate tag (e.g., a video or audio
            element). The video element MUST have a unique origin so that it is
            inaccessible to the content JS. This is the same security mechanism
            as is used with an ordinary audio or video element which has a src=
            property from a separate origin.</p>
          </li>


          <li>
            <p>Used as the argument to addStream() for a PeerConnection,
            subject to the restrictions detailed in the WebRTC document.</p>
          </li>
        </ul>


        <p>When the noaccess=true constraint applies to a track, that track may
        be added to any PeerConnection.</p>


        <p class="note">Open Issue: The editors worry that the above paragraph
        is just wrong. If the track can be added to a PeerConnection that is
        connect to another PeerConenction in the same application, the
        application could get access to the data. We sugest this should be
        changed from "may be added" to "may not be added". This will allow
        noaccess=true to be used for things like hair check dialogs.</p>


        <p>When the peerIdentity=foo constraint applies to a track, then that
        track may be added only to PeerConnections with compatible peer
        identities as described in the WebRTC document.</p>


        <p>Both the noaccess and peerIdentity constraints must be mandatory.
        Any use of them in the optional block must trigger an error.</p>
      </section>
    </section>


    <section>
      <h3>MediaStreamTrackEvent</h3>


      <p>The <code><a href="#event-mediastream-addtrack">addtrack</a></code>
      and <code title="event-MediaStreamTracklist-removetrack"><a href=
      "#event-mediastream-removetrack">removetrack</a></code> events use the
      <code><a>MediaStreamTrackEvent</a></code> interface.</p>


      <p><dfn title="Fire a track event">Firing a track event named
      <var>e</var></dfn> with a <code><a>MediaStreamTrack</a></code>
      <var>track</var> means that an event with the name <var>e</var>, which
      does not bubble (except where otherwise stated) and is not cancelable
      (except where otherwise stated), and which uses the
      <code><a>MediaStreamTrackEvent</a></code> interface with the
      <code><a href="#dom-mediastreamtrackevent-track">track</a></code>
      attribute set to <var>track</var>, MUST be created and dispatched at the
      given target.</p>


      <dl class="idl" data-merge="MediaStreamTrackEventInit" title=
      "interface MediaStreamTrackEvent : Event">
        <dt>Constructor(DOMString type, MediaStreamTrackEventInit
        eventInitDict)</dt>


        <dd>TODO</dd>


        <dt>readonly attribute MediaStreamTrack track</dt>


        <dd>
          <p>The <dfn id=
          "dom-mediastreamtrackevent-track"><code>track</code></dfn> attribute
          represents the <code><a>MediaStreamTrack</a></code> object associated
          with the event.</p>
        </dd>
      </dl>


      <dl class="idl" title="dictionary MediaStreamTrackEventInit : EventInit">
        <dt>MediaStreamTrack? track</dt>


        <dd>
          <p>TODO</p>
        </dd>
      </dl>
    </section>


    <section>
      <h2>Video and Audio Tracks</h2>


      <p>The <code><a>MediaStreamTrack</a></code> object cannot be instantiated
      directly. To create an instance of a
      <code><a>MediaStreamTrack</a></code>, one of its derived track types may
      be instantiated. These derived types are defined in this section.</p>


      <p>Note that the camera's <q>green light</q> doesn't come on when a new
      track is created; nor does the user get prompted to enable the
      camera/microphone. Those actions only happen after the developer has
      requested that a media stream containing <code>"new"</code> tracks be
      bound to a source via <code><a>getUserMedia()</a></code>. Until that
      point tracks are inert.</p>


      <section>
        <h2>VideoStreamTrack interface</h2>


        <p>Video tracks may be instantiated with optional media track
        constraints. These constraints can be later modified on the track as
        needed by the application, or created after-the-fact if the initial
        constraints are unknown to the application.</p>


        <div class="note">
          <p><strong>Example:</strong> <code><a>VideoStreamTrack</a></code>
          objects are instantiated in JavaScript using the new operator:</p>

          <pre xml:space="preserve" class="example highlight">
new VideoStreamTrack();
</pre>or

          <pre xml:space="preserve" class="example highlight">
new VideoStreamTrack({
    "optional": [{
        sourceId: "20983-20o198-109283-098-09812"
    }, {
        width: {
            min: 800,
            max: 1200
        }
    }, {
        height: {
            min: 600
        }
    }]
});
</pre>
        </div>


        <dl class="idl" title="interface VideoStreamTrack : MediaStreamTrack">
          <dt>Constructor(optional Constraints videoConstraints)</dt>


          <dd>TODO</dd>
        </dl>
      </section>


      <section>
        <h2>AudioStreamTrack</h2>


        <div class="note">
          <p><strong>Example:</strong> <code><a>AudioStreamTrack</a></code>
          objects are instantiated in JavaScript using the new operator:</p>

          <pre xml:space="preserve" class="example highlight">
new AudioStreamTrack();
</pre>or

          <pre xml:space="preserve" class="example highlight">
new AudioStreamTrack({
    optional: [{
        sourceId: "64815-wi3c89-1839dk-x82-392aa"
    }, {
        gain: 0.5
    }]
});
</pre><!-- TODO - gain in above example should be long or double to match -->
          <!-- spec. Probably wrong the way it is now -->
        </div>


        <dl class="idl" title="interface AudioStreamTrack : MediaStreamTrack">
          <dt>Constructor(optional Constraints audioConstraints)</dt>


          <dd>TODO</dd>
        </dl>
      </section>
    </section>
  </section>


  <section>
    <h2>The model: sources, sinks, constraints, and states</h2>


    <p>Browsers provide a media pipeline from sources to sinks. In a browser,
    sinks are the &lt;img&gt;, &lt;video&gt; and &lt;audio&gt; tags.
    Traditional sources include camera, microphones, streamed content, files
    and web resources. The media produced by these sources typically does not
    change over time - these sources can be considered to be static.</p>


    <p>The sinks that display these sources to the user (the actual tags
    themselves) have a variety of controls for manipulating the source content.
    For example, an &lt;img&gt; tag scales down a huge source image of
    1600x1200 pixels to fit in a rectangle defined with
    <code>width="400"</code> and <code>height="300"</code>.</p>


    <p>The getUserMedia API adds dynamic sources such as microphones and
    cameras - the characteristics of these sources can change in response to
    application needs. These sources can be considered to be dynamic in nature.
    A &lt;video&gt; element that displays media from a dynamic source can
    either perform scaling or it can feed back information along the media
    pipeline and have the source produce content more suitable for display.</p>


    <div class="note">
      <p><strong>Note:</strong> This sort of feedback loop is obviously just
      enabling an "optimization", but it's a non-trivial gain. This
      optimization can save battery, allow for less network congestion,
      etc...</p>
    </div>


    <p>Note that <code>MediaStream</code> sinks (such as
    <code>&lt;video&gt;</code>, <code>&lt;audio&gt;</code>, and even
    <code>RTCPeerConnection</code>) will continue to have mechanisms to further
    transform the source stream beyond that which the <a>Settings</a>,
    <a>Capabilities</a>, and <a>Constraints</a> described in this specification
    offer. (The sink transformation options, including those of
    <code>RTCPeerConnection</code>, are outside the scope of this
    specification.)</p>


    <p>The act of changing or applying a track constraint may affect the
    <code><a>settings</a></code> of all tracks sharing that source and
    consequently all down-level sinks that are using that source. Many sinks
    may be able to take these changes in stride, such as the
    <code>&lt;video&gt;</code> element or <code>RTCPeerConnection</code>.
    Others like the Recorder API may fail as a result of a source state
    change.</p>


    <p>The <code>RTCPeerConnection</code> is an interesting object because it
    acts simultaneously as both a sink <strong>and</strong> a source for
    over-the-network streams. As a sink, it has source transformational
    capabilities (e.g., lowering bit-rates, scaling-up or down resolutions,
    adjusting frame-rates), and as a source it could have its own states
    changed by a track source (though in this specification sources with the
    <code><a>remote</a></code> attribute set to true do not consider the
    current constraints applied to a track).</p>


    <p>To illustrate how changes to a given source impact various sinks,
    consider the following example. This example only uses width and height,
    but the same principles apply to any of the <a>Settings</a> exposed in this
    proposal. In the first figure a home client has obtained a video source
    from its local video camera. The source's width and height state are 800
    pixels by 600 pixels, respectively. Three <code><a>MediaStream</a></code>
    objects on the home client contain tracks that use this same
    <code><a>sourceId</a></code>. The three media streams are connected to
    three different sinks: a <code>&lt;video&gt;</code> element (A), another
    <code>&lt;video&gt;</code> element (B), and a peer connection (C). The peer
    connection is streaming the source video to an away client. On the away
    client there are two media streams with tracks that use the peer connection
    as a source. These two media streams are connected to two
    <code>&lt;video&gt;</code> element sinks (Y and Z).</p>
    <img alt=
    "Changing media stream source effects: before the requested change" src=
    "images/change_states_before.png" />

    <p>Note that at this moment, all of the sinks on the home client must apply
    a transformation to the original source's provided dimension settings. A is
    scaling the video up (resulting in loss of quality), B is scaling the video
    down, and C is also scaling the video up slightly for sending over the
    network. On the away client, sink Y is scaling the video way down, while
    sink Z is not applying any scaling.</p>


    <p>Using the <a>Constrainable</a> interface, the home client's video source
    is changed to a higher resolution (1920 by 1200 pixels).</p>
    <img alt="Changing media stream source effects: after the requested change"
    src="images/change_states_after.png" />

    <p>Note that the source change immediately affects all of the sinks on the
    home client, but does not impact any of the sinks (or sources) on the away
    client. With the increase in the home client source video's dimensions,
    sink A no longer has to perform any scaling, while sink B must scale down
    even further than before. Sink C (the peer connection) must now scale down
    the video in order to keep the transmission constant to the away
    client.</p>


    <p>While not shown, an equally valid settings change request could be made
    of the away client video source (the peer connection on the away client's
    side). This would not only impact sink Y and Z in the same manner as
    before, but would also cause re-negotiation with the peer connection on the
    home client in order to alter the transformation that it is applying to the
    home client's video source. Such a change <strong>would not</strong> change
    anything related to sink A or B or the home client's video source.</p>


    <p>Note that this specification does not define a mechanism by which a
    change to the away client's video source could automatically trigger a
    change to the home client's video source. Implementations may choose to
    make such source-to-sink optimizations as long as they only do so within
    the constraints established by the application, as the next example
    demonstrates.</p>


    <p>It is fairly obvious that changes to a given source will impact sink
    consumers. However, in some situations changes to a given sink may also be
    cause for implementations to adjust the characteristics of a source's
    stream. This is illustrated in the following figures. In the first figure
    below, the home client's video source is sending a video stream sized at
    1920 by 1200 pixels. The video source is also unconstrained, such that the
    exact source dimensions are flexible as far as the application is
    concerned. Two <code><a>MediaStream</a></code> objects contain tracks with
    the same <code><a>sourceId</a></code>, and those
    <code><a>MediaStream</a></code>s are connected to two different
    <code>&lt;video&gt;</code> element sinks A and B. Sink A has been sized to
    <code>width="1920"</code> and <code>height="1200"</code> and is displaying
    the source's video content without any transformations. Sink B has been
    sized smaller and, as a result, is scaling the video down to fit its
    rectangle of 320 pixels across by 200 pixels down.</p>
    <img alt=
    "Changing media stream sinks may affect sources: before the requested change"
    src="images/change_states_before2.png" />

    <p>When the application changes sink A to a smaller dimension (from 1920 to
    1024 pixels wide and from 1200 to 768 pixels tall), the browser's media
    pipeline may recognize that none of its sinks require the higher source
    resolution, and needless work is being done both on the part of the source
    and on sink A. In such a case and without any other constraints forcing the
    source to continue producing the higher resolution video, the media
    pipeline MAY change the source resolution:</p>
    <img alt=
    "Changing media stream sinks may affect sources: after the requested change"
    src="images/change_states_after2.png" />

    <p>In the above figure, the home client's video source resolution was
    changed to the greater of that from sinkA and from sinkB in order to
    optimize playback. While not shown above, the same behavior could apply to
    peer connections and other sinks.</p>


    <p>It is possible that <a>constraints</a> can be applied to a track which a
    source is unable to satisfy. When this happens, the user agent is required
    to fire an <a>overconstrained</a> MediaErrorEvent to the track informing it
    of this condition, and the track becomes muted. There is no mandatory
    side-effect on the source itself as a result of this condition.</p>


    <p>When multiple tracks share the same source (as illustrated in the
    previous figures), it is also possible that two (or more) tracks can apply
    contradictory constraints on the source. Since there is only a single
    thread of control, it is always possible for the browser to determine which
    track created the overconstrained condition. In this situation, the user
    agent MUST send the <a>overconstrained</a> MediaErrorEvent only to the
    track that created the condition and MUST not apply any of the constraints
    newly requested for that track. Here is an example of this behavior.</p>


    <p>In this example, two media streams each have a video track that share
    the same source. The first track has a mandatory constraint forcing on the
    source's fill light. That track is connected to sink N. Sink N has a width
    and height of 800 by 600 pixels and is scaling down the source's resolution
    of 1024 by 768 to fit. The other track initially has no constraints
    applied; it is connected to sink P. Sink P has a width and height equal to
    that of the source.</p>


    <p><img alt="Overconstrained" src="images/overconstrained_before.png" />
    </p>


    <p>Now, the second track adds a mandatory constraint that the fill light
    should be forced off. At this point, both mandatory constraints cannot be
    satisfied by the source (the fill light cannot be simultaneously on and off
    at the same time). The second track is transitioned into the muted state
    and receives an <a>overconstrained</a> event. At the same time, the source
    notes that its remaining active sink only requires a resolution of 800 by
    600 and so it adjusts its resolution down to match (this is an optional
    optimization that the user agent is allowed to make given the
    situation).</p>


    <p>At this point, it is the responsibility of the application to fix the
    problem that led to the overconstrained situation (by either removing the
    fill light mandatory constraint on the second track, or by
    changing/removing the fill light mandatory constraint on the first
    track).</p>


    <p><img alt="Overconstrained Result" src=
    "images/overconstrained_after.png" />
    </p>
  </section>


  <section>
    <h2>MediaStreams as Media Elements</h2>


    <p>A <code>MediaStream</code> may be assigned to media elements as defined
    in <a href=
    "http://www.w3.org/TR/html5/embedded-content-0.html#media-elements">HTML5</a>
    [[HTML5]] A <code>MediaStream</code> is not preloadable or seekable and
    represents a simple, potentially infinite, linear media timeline. The
    timeline starts at 0 and increments linearly in real time as long as the
    <code>MediaStream</code> is playing. The timeline does not increment when
    the <code>MediaStream</code> is paused.</p>


    <section>
      <h3>Direct Assignment to Media Elements</h3>


      <p>UAs that support this specification MUST support the following partial
      interface, which allows a MediaStream to be assigned directly to a media
      element.</p>


      <dl class="idl" title="partial interface HTMLMediaElement">
        <dt>attribute MediaStream? srcObject</dt>


        <dd>
          <p>Holds the MediaStream that provides media for this element. This
          attribute overrides both the <code>src</code> attribute and any
          &lt;source&gt; elements. Specifically, if <code>srcObject</code> is
          specified, the UA MUST use it as the source of media, even if the
          <code>src</code> attribute is also set or &lt;source&gt; children are
          present. If the value of <code>srcObject</code> is replaced or set to
          null the UA MUST re-run the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a></p>
        </dd>
      </dl>


      <p class="issue">We may want to allow direct assignment of other types as
      well</p>
    </section>


    <section>
      <h3>Loading and Playing a MediaStream in a Media Element</h3>


      <p>The UA runs the <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
      media element load algorithm</a> to obtain media for the media element to
      display. As defined in the [[HTML5]] specification, this algorithm has
      two basic phases: <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-algorithm">
      resource selection algorithm</a> chooses the resource to play and
      resolves its URI. Then the <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
      resource fetch phase</a> loads the resource. Both these phases are
      potentially simplified when using a MediaStream. First of all,
      <code>srcObject</code> takes priority over other means of specifying the
      resource, and it provides the object itself rather than a URI. Therefore,
      there is no need to run the resource selection algorithm. Secondly, when
      the UA reaches the resource fetch algorithm with a MediaStream, the
      MediaStream is a local object so there's nothing to fetch. Therefore, the
      following modifications/restrictions to the <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
      media element load algorithm</a> apply:</p>


      <ul>
        <li>
          <p>Whenever the user agent runs the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, if <code>srcObject</code> is
          specified, the UA must immediately go to the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
          resource fetch phase</a> of the algorithm.</p>
        </li>


        <li>
          <p>Whenever the user agent runs the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, reaches the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
          resource fetch phase</a> of this algorithm, and determines that the
          media resource in question is a MediaStream, it MUST immediately
          abort the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-algorithm">
          resource selection algorithm</a>, setting the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-readystate">
          <code>media.readyState</code></a> to HAVE_NOTHING if media is not yet
          available and to HAVE_ENOUGH_DATA once it is.</p>
        </li>


        <li>
          <p>For each <code><a>MediaStreamTrack</a></code> in the
          <code><a>MediaStream</a></code>, including those that are added after
          the UA enters the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, the UA MUST create a corresponding
          <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#audiotrack">AudioTrack</a></code>
          or <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#videotrack">VideoTrack</a></code>
          as defined in [[HTML5]]. Since the order in the
          <code><a>MediaStream</a></code>'s <a href="#track-set">track set</a>
          is undefined, no requirements are put how the <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#audiotracklist">AudioTrackList</a></code>
          and <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#videotracklist">VideoTrackList</a></code>
          are ordered.</p>


          <p>The properties of the <code>AudioTrack</code> and
          <code>VideoTrack</code> objects MUST be initialized as follows.
          Let</p>


          <ul>
            <li>
              <p><code>AudioTrack.id</code> and <code>VideoTrack.id</code> have
              the value of the corresponding <code><a href=
              "#dom-mediastreamtrack-id">MediaStreamTrack.id</a></code>
              attribute</p>
            </li>


            <li>
              <p><code>AudioTrack.kind</code> and <code>VideoTrack.kind</code>
              be <code>"main"</code></p>
            </li>


            <li>
              <p><code>AudioTrack.label</code> and
              <code>VideoTrack.label</code> have the value of the corresponding
              <code><a href=
              "#dom-mediastreamtrack-label">MediaStreamTrack.label</a></code>
              attribute</p>
            </li>


            <li>
              <p><code>AudioTrack.language</code> and
              <code>VideoTrack.language</code> be the empty string</p>
            </li>


            <li>
              <p><code>AudioTrack.enabled</code> be <code>true</code></p>
            </li>
          </ul>


          <p>Set the <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-videotracklist-selectedindex">
          VideoTrackList.selectedIndex</a></code> to the index of the first
          <code>VideoTrack</code>, in the <code>VideoTrackList</code>, that
          corresponds to a <code><a>MediaStreamTrack</a></code> that is not
          <a href="#track-muted">muted</a> or <a href=
          "#track-enabled">disabled</a>. If no such <code>VideoTrack</code>
          exists, set the <code>selectedIndex</code> attribute to 0.</p>


          <p>(Note that since the MediaStream is potentially endless, the UA
          does not exit the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a> until the MediaStream moves from the
          active to the <a href="#stream-inactive">inactive</a> state.)</p>
        </li>


        <li>
          <p>If a <code><a>MediaStreamTrack</a></code> is removed from a
          <code><a>MediaStream</a></code>, played by a media element, the
          corresponding <code>AudioTrack</code> or <code>VideoTrack</code> MUST
          be removed as well.</p>
        </li>


        <li>
          <p>The UA MUST NOT buffer data from a MediaStream. When playing, the
          UA MUST always play the current data from the stream.</p>
        </li>


        <li>
          <p>When the MediaStream is moves from the active to the <a href=
          "#stream-inactive">inactive</a> state, the UA MUST raise an <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#event-media-ended">
          ended</a> event on the media element and set its <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-ended">ended</a>
          attribute to <code>true</code>. Note that once <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-ended">ended</a>
          equals <code>true</code> the media element will not play media even
          if new Tracks are added to the MediaStream (causing it to return to
          the active state) unless <code>autoplay</code> is <code>true</code>
          or the JavaScript restarts the element, e.g., by calling <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-play">play()</a>.</p>
        </li>
      </ul>
    </section>


    <section>
      <h3>Media Element Attributes when Playing a MediaStream</h3>


      <p>The nature of the <code>MediaStream</code> places certain restrictions
      on the behavior and attribute values of the associated media element and
      on the operations that can be performed on it, as shown below:</p>


      <table class="simple">
        <caption>
          Legal values for the properties of a media element bound to a
          MediaStream
        </caption>


        <thead>
          <tr>
            <th scope="col">Attribute Name</th>

            <th scope="col">Attribute Type</th>

            <th scope="col">Valid Values When Using a MediaStream</th>

            <th scope="col">Additional considerations</th>
          </tr>
        </thead>


        <tbody>
          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currentsrc"
              class="externalDFN"><code>currentSrc</code></a>
            </td>

            <td><code>DOMString</code>
            </td>

            <td>the empty string</td>

            <td>When <code>srcObject</code> is specified the UA MUST set this
            to the empty string.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#attr-media-preload"
              class="externalDFN"><code>preload</code></a>
            </td>

            <td><code>DOMString</code>
            </td>

            <td><code>none</code>
            </td>

            <td>A MediaStream cannot be preloaded.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-buffered"
              class="externalDFN"><code>buffered</code></a>
            </td>

            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"
              class="externalDFN"><code>TimeRanges</code></a>
            </td>

            <td><code>buffered.length</code> MUST return <code>0</code>.</td>

            <td>A MediaStream cannot be preloaded. Therefore, the amount
            buffered is always an empty TimeRange.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-networkstate"
              class="externalDFN"><code>networkState</code></a>
            </td>

            <td><code>unsigned short</code>
            </td>

            <td>NETWORK_IDLE</td>

            <td>The media element does not fetch the MediaStream so there is no
            network traffic.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-readystate"
              class="externalDFN"><code>readyState</code></a>
            </td>

            <td><code>unsigned short</code>
            </td>

            <td>HAVE_NOTHING, HAVE_ENOUGH_DATA</td>

            <td>A <code><a>MediaStream</a></code> may be created before there
            is any data available, for example when a stream is received from a
            remote peer. The value of the <code>readyState</code> of the media
            element MUST be HAVE_NOTHING before the first media arrives and
            HAVE_ENOUGH_DATA once the first media has arrived.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime"
              class="externalDFN"><code>currentTime</code></a>
            </td>

            <td><code>double</code>
            </td>

            <td>Any positive integer. The initial value is 0 and the values
            increments linearly in real time whenever the stream is
            playing.</td>

            <td>The value is the current stream position, in seconds. On any
            attempt to set this attribute, the user agent must throw an
            <code>InvalidStateError</code> exception.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-duration"
              class="externalDFN"><code>duration</code></a>
            </td>

            <td><code>unrestricted double</code>
            </td>

            <td>Infinity</td>

            <td>A MediaStream does not have a pre-defined duration.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-seeking"
              class="externalDFN"><code>seeking</code></a>
            </td>

            <td><code>boolean</code>
            </td>

            <td>false</td>

            <td>A MediaStream is not seekable. Therefore, this attribute MUST
            always have the value <code>false</code>.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-defaultplaybackrate"
              class="externalDFN"><code>defaultPlaybackRate</code></a>
            </td>

            <td><code>double</code>
            </td>

            <td>1.0</td>

            <td>A MediaStream is not seekable. Therefore, this attribute MUST
            always have the value <code>1.0</code> and any attempt to alter it
            MUST fail.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-playbackrate"
              class="externalDFN"><code>playbackRate</code></a>
            </td>

            <td><code>double</code>
            </td>

            <td>1.0</td>

            <td>A MediaStream is not seekable. Therefore, this attribute MUST
            always have the value <code>1.0</code> and any attempt to alter it
            MUST fail.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-played"
              class="externalDFN"><code>played</code></a>
            </td>

            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"
              class="externalDFN"><code>TimeRanges</code></a>
            </td>

            <td>
              <code>played.length</code> MUST return <code>1</code>.<br />
              <code>played.start(0)</code> MUST return <code>0</code>.<br />
              <code>played.end(0)</code> MUST return the last known <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime"
              class="externalDFN"><code>currentTime</code></a>.
            </td>

            <td>A MediaStream's timeline always consists of a single range,
            starting at 0 and extending up to the currentTime.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-seekable"
              class="externalDFN"><code>seekable</code></a>
            </td>

            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"
              class="externalDFN"><code>TimeRanges</code></a>
            </td>

            <td>
              <code>seekable.length</code> MUST return <code>0</code>.<br />
              <code>seekable.start()</code> MUST return <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime"
              class="externalDFN"><code>currentTime</code></a>.<br />
              <code>seekable.end()</code> MUST return <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime"
              class="externalDFN"><code>currentTime</code></a>.
            </td>

            <td>A MediaStream is not seekable.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-startdate"
              class="externalDFN"><code>startDate</code></a>
            </td>

            <td><code>Date</code>
            </td>

            <td>Not-a-Number (NaN)</td>

            <td>A MediaStream does not specify a timeline offset.</td>
          </tr>


          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-loop"
              class="externalDFN"><code>loop</code></a>
            </td>

            <td><code>boolean</code>
            </td>

            <td>true, false</td>

            <td>Setting the <code>loop</code> attribute has no effect since a
            <code><a>MediaStream</a></code> has no defined end and therefore
            cannot be looped.</td>
          </tr>
        </tbody>
      </table>
    </section>
  </section>


  <section>
    <h2>Error Handling</h2>


    <p>All errors defined in this specification implement the following
    interface:</p>


    <dl class="idl" title="[NoInterfaceObject] interface MediaError">
      <dt>readonly attribute DOMString name</dt>


      <dd>
        <p>The name of the error</p>
      </dd>


      <dt>readonly attribute DOMString? message</dt>


      <dd>A UA-dependent string offering extra human-readable information about
      the error.</dd>


      <dt>readonly attribute DOMString? constraintName</dt>


      <dd>
        <p>This attribute is only used for some types of errors. For
        <code><a>MediaError</a></code> with a name of
        <code>ConstraintNotSatisfiedError</code>, this attribute MUST be set to
        the name of the constraint that caused the error.</p>
      </dd>
    </dl>


    <div class="note">
      Open Issue: We may make MediaError inherit from DOMError once the
      definition of DOMError is stable.
    </div>


    <div class="note">
      Open Issue: Do we want to allow the constraintName attribute to contain
      multiple constraint names? In many cases the error is raised as soon as a
      single unsatisfied mandatory constraint is found, but in others it may be
      possible to determine that multiple constraints are not satisfied.
    </div>


    <p>The following interface is defined for cases when a MediaError is raised
    as an event:</p>


    <dl class="idl" data-merge="MediaErrorEventInit" title=
    "interface MediaErrorEvent : Event">
      <dt>Constructor(DOMString type, MediaErrorEventInit eventInitDict)</dt>


      <dd>TODO</dd>


      <dt>readonly attribute MediaError error</dt>


      <dd>TODO</dd>
    </dl>


    <dl class="idl" title="dictionary MediaErrorEventInit : EventInit">
      <dt>MediaError error</dt>


      <dd>
        <p>TODO</p>
      </dd>
    </dl>
  </section>


  <section class="informative">
    <h2>Event summary</h2>


    <p>The following event fires on <code><a>MediaStream</a></code>
    objects:</p>


    <table>
      <tr>
        <th>Event name</th>

        <th>Interface</th>

        <th>Fired when...</th>
      </tr>


      <tbody>
        <tr>
          <td><dfn id="event-mediastream-active"><code>active</code></dfn>
          </td>

          <td><code>Event</code>
          </td>

          <td>
            The <code><a>MediaStream</a></code> became active (see <a href=
            "#stream-inactive">inactive</a>).
          </td>
        </tr>


        <tr>
          <td><dfn id="event-mediastream-inactive"><code>inactive</code></dfn>
          </td>

          <td><code>Event</code>
          </td>

          <td>
            The <code><a>MediaStream</a></code> became <a href=
            "#stream-inactive">inactive</a>.
          </td>
        </tr>


        <tr>
          <td><dfn id="event-mediastream-addtrack"><code>addtrack</code></dfn>
          </td>

          <td><code><a>MediaStreamTrackEvent</a></code>
          </td>

          <td>A new <code><a>MediaStreamTrack</a></code> has been added to this
          stream. Note that this event is not fired when the script directly
          modifies the tracks of a <code><a>MediaStream</a></code>.</td>
        </tr>


        <tr>
          <td><dfn id=
          "event-mediastream-removetrack"><code>removetrack</code></dfn>
          </td>

          <td><code><a>MediaStreamTrackEvent</a></code>
          </td>

          <td>A <code><a>MediaStreamTrack</a></code> has been removed from this
          stream. Note that this event is not fired when the script directly
          modifies the tracks of a <code><a>MediaStream</a></code>.</td>
        </tr>
      </tbody>
    </table>


    <p>The following event fires on <code><a>MediaStreamTrack</a></code>
    objects:</p>


    <table>
      <tr>
        <th>Event name</th>

        <th>Interface</th>

        <th>Fired when...</th>
      </tr>


      <tbody>
        <tr>
          <td><dfn id=
          "event-mediastreamtrack-started"><code>started</code></dfn>
          </td>

          <td><code>Event</code>
          </td>

          <td>The <code><a>MediaStreamTrack</a></code> object has just
          transitioned from the "new" <code><a>readyState</a></code> to another
          state. This event fires before any other corresponding events such as
          "ended" or "statechanged".</td>
        </tr>


        <tr>
          <td><dfn id="event-mediastreamtrack-mute"><code>mute</code></dfn>
          </td>

          <td><code>Event</code>
          </td>

          <td>The <code><a>MediaStreamTrack</a></code> object's source is
          temporarily unable to provide data.</td>
        </tr>


        <tr>
          <td><dfn id="event-mediastreamtrack-unmute"><code>unmute</code></dfn>
          </td>

          <td><code>Event</code>
          </td>

          <td>The <code><a>MediaStreamTrack</a></code> object's source is live
          again after having been temporarily unable to provide data.</td>
        </tr>


        <tr>
          <td><dfn id=
          "event-mediastreamtrack-overconstrained"><code>overconstrained</code></dfn>
          </td>

          <td><code>MediaErrorEvent</code>
          </td>

          <td>
            <p>This error event fires asynchronously for each affected track
            (when multiple tracks share the same source) after the user agent
            has evaluated the current constraints against a given
            <code><a>sourceId</a></code> and is not able to configure the
            source within the limitations established by the union of imposed
            constraints.</p>


            <p>Due to being over-constrained, the user agent must mute each
            affected track.</p>


            <p>The affected track(s) will remain un-usable (in the
            <code>"muted"</code> <a>readyState</a>) until the application
            adjusts the constraints to accommodate the source's
            capabilities.</p>
          </td>
        </tr>


        <tr>
          <td><dfn id="event-mediastreamtrack-ended"><code>ended</code></dfn>
          </td>

          <td><code>Event</code>
          </td>

          <td>The <code><a>MediaStreamTrack</a></code> object's source will no
          longer provide any data, either because the user revoked the
          permissions, or because the source device has been ejected, or
          because the remote peer stopped sending data, or because the
          <code><a href="#widl-MediaStreamTrack-stop-void">stop()</a></code>
          method was invoked.</td>
        </tr>
      </tbody>
    </table>
  </section>
  <!-- TODO CULLEN FIX no idea why must remove this   </section> -->


  <section id="enumerating-devices">
    <h2>Enumerating Local Media Devices</h2>


    <p>This section describes an API that the script can use to query the user
    agent about connected media input and output devices.</p>


    <section>
      <h3>NavigatorUserMedia</h3>


      <dl class="idl" title="[NoInterfaceObject] interface NavigatorUserMedia">
        <dt>void getMediaDevices(MediaDeviceInfoCallback resultCallback)</dt>


        <dd>
          <p>Collects information about the user agents available media input
          and output devices; for example a web camera or a headset. The method
          MUST only return information that the script is authorized to access
          (TODO expand authorized).</p>


          <p>When the <dfn id=
          "dom-navigator-getmediadevices"><code>getMediaDevices()</code></dfn>
          method is called, the user agent must queue a task that runs the
          following steps:</p>


          <ol>
            <li>
              <p>Let <var>resultCallback</var> be the callback indicated by the
              methods first argument.</p>
            </li>


            <li>
              <p>If this method has been called previously within this
              application session, let <var>oldList</var> be the list of
              <code><a>MediaDeviceInfo</a></code> objects that was produced at
              that call (<var>resultList</var>); otherwise, let
              <var>oldList</var> be an empty list.</p>
            </li>


            <li>
              <p>Let <var>resultList</var> be an empty list.</p>
            </li>


            <li>
              <p>Probe the user agent for available media devices, and run the
              following sub steps for each discovered device,
              <var>device</var>:</p>


              <ol>
                <li>
                  <p>If <var>device</var> is represented by a
                  <code><a>MediaDeviceInfo</a></code> object in
                  <var>oldList</var>, append that object to
                  <var>resultList</var>, abort these steps and continue with
                  the next device (if any).</p>
                </li>


                <li>
                  <p>Let <var>deviceInfo</var> be a new
                  <code><a>MediaDeviceInfo</a></code> object to represent
                  <var>device</var>.</p>
                </li>


                <li>
                  <p>If <var>device</var> belongs to the same physical device
                  as a device, already represented in <var>oldList</var> or
                  <var>resultList</var>, initialize <var>deviceInfo</var>'s
                  <code><a href=
                  "#widl-MediaDeviceInfo-groupId">groupId</a></code> member to
                  the <code><a href=
                  "#widl-MediaDeviceInfo-groupId">groupId</a></code> value of
                  the existing <code><a>MediaDeviceInfo</a></code> object.
                  Otherwise, let <var>deviceInfo</var>'s <code><a href=
                  "#widl-MediaDeviceInfo-groupId">groupId</a></code> member be
                  a newly generated unique identifier</p>
                </li>


                <li>
                  <p>Append <var>deviceInfo</var> to <var>resultList</var>.</p>
                </li>
              </ol>
            </li>


            <li>
              <p>Invoke <var>resultCallback</var> with <var>resultList</var> as
              its argument.</p>
            </li>
          </ol>
        </dd>
      </dl>


      <div class="idl" title="Navigator implements NavigatorUserMedia">
      </div>
    </section>


    <section>
      <h2>Device Info</h2>


      <dl class="idl" title="callback MediaDeviceInfoCallback = void">
        <dt>sequence&lt;MediaDeviceInfo&gt; deviceInfoList</dt>


        <dd>A sequence of <code><a>MediaDeviceInfo</a></code> objects
        representing the result of a call to <code><a href=
        "#dom-navigator-getmediadevices">Navigator.getMediaDevices()</a></code>
        .</dd>
      </dl>


      <div class="note">
        The old SourceInfo dictionary used to refer to the MediaSourceStates
        dictionary. That dictionary is no longer available when Constrainable
        is introduced. When Constrainable lands, we should see if we can align
        deviceId, kind and label, below, with the new definitions of source
        capabilities.
      </div>


      <dl class="idl" title="dictionary MediaDeviceInfo">
        <dt>DOMString deviceId</dt>


        <dd>
          <p>The unique id for the represented device.</p>
        </dd>


        <dt>MediaDeviceKind kind</dt>


        <dd>
          <p>Describes the kind of the represented device.</p>
        </dd>


        <dt>DOMString label</dt>


        <dd>
          <p>A label describing this device (for example "External USB
          Webcam"). If the device has no associated label, then this dictionary
          member MUST return the empty string.</p>
        </dd>


        <dt>DOMString groupId</dt>


        <dd>
          <p>Returns the group identifier of the represented device. Two
          devices has the same group identifier if they belong to the same
          physical device; for example a headset.</p>
        </dd>
      </dl>


      <dl class='idl' title='enum MediaDeviceKind'>
        <dt>audioinput</dt>


        <dd>
          <p>Represents an audio input device; for example a microphone.</p>
        </dd>


        <dt>audiooutput</dt>


        <dd>
          <p>Represents an audio output device; for example a pair of
          headphones.</p>
        </dd>


        <dt>videoinput</dt>


        <dd>
          <p>Represents a video input device; for example a webcam.</p>
        </dd>
      </dl>
    </section>
  </section>


  <section id="local-content">
    <h2>Obtaining local multimedia content</h2>


    <section>
      <h2>NavigatorUserMedia</h2>


      <dl class="idl" title="partial interface NavigatorUserMedia">
        <dt>void getUserMedia(MediaStreamConstraints? constraints,
        NavigatorUserMediaSuccessCallback successCallback,
        NavigatorUserMediaErrorCallback errorCallback)</dt>


        <dd>
          <p>Prompts the user for permission to use their Web cam or other
          video or audio input.</p>


          <p class="issue">The syntax for getUserMedia() is still under
          discussion. Some questions are: whether it creates media streams or
          just initializes ones already created; whether it creates streams
          synchronously (immediate return of MediaStream with callback later
          when user grants permission) or asynchronously (MediaStream available
          only upon callback).</p>


          <p>The <var>constraints</var> argument is an object of type
          <code><a>MediaStreamConstraints</a></code>.</p>


          <p>The <var>successCallback</var> will be invoked with a suitable
          <code><a>MediaStream</a></code> object as its argument if the user
          accepts valid tracks as described below.</p>


          <p>The <var>errorCallback</var> will be invoked if there is a failure
          in finding valid tracks or if the user denies permission, both as
          described below.</p>


          <p>When the <dfn id=
          "dom-navigator-getusermedia"><code>getUserMedia()</code></dfn> method
          is called, the user agent MUST run the following steps:</p>


          <ol>
            <li>
              <p>Let <var>constraints</var> be the method's first argument.</p>
            </li>


            <li>
              <p>Let <var>successCallback</var> be the callback indicated by
              the method's second argument.</p>
            </li>


            <li>
              <p>Let <var>errorCallback</var> be the callback indicated by the
              method's third argument.</p>
            </li>


            <li>
              <p>Let <var>requestedMediaTypes</var> be the set of media types
              in <var>constraints</var> with either a dictionary value or a
              value of "true".</p>
            </li>


            <li>
              <p>If <var>requestedMediaTypes</var> is the empty set, let
              <var>error</var> be a new <code><a>MediaError</a></code> object
              whose <code><a>name</a></code> attribute has the value
              <code>NotSupportedError</code> and jump to the step labeled
              <em>Error Task</em> below.</p>
            </li>


            <li>
              <p>Let <var>finalSet</var> be an (initially) empty set.</p>
            </li>


            <li>
              <p>If <var>successCallback</var> is null, abort these steps.</p>
            </li>
            <!-- we could throw an exception instead (that's
   why the method doesn't return until later: so that we can add an
   exception here, or for /options/ below, without changing the
   algorithm) -->
            <!--
            <li>
              <p>For each member of the <code><a>MediaStreamOptions</a></code>
              dictionary create a local representation and set it to false.</p>
            </li>

            <li>
              <p>For each property in <var>options</var> that is present and
              set to true, let the corresponding local representation be
              true.</p>
            </li>

            <li>
              <p>If none of the local representations of the
              <code><a>MediaStreamOptions</a></code> dictionary members is set
              to true, then throw a <code>NOT_SUPPORTED_ERR</code> exception
              and abort these steps.</p>
            </li>
-->


            <li>
              <p>For each media type <var>T</var> in
              <var>requestedMediaTypes</var>,</p>


              <ol>
                <li>
                  <p>Let <var>candidateSet</var> be all possible tracks of
                  media type <var>T</var> that the browser could return.</p>
                </li>


                <li>If the value of the <var>T</var> entry of
                <var>constraints</var> is "true", jump to the step labeled
                <em>final</em> below. Otherwise, continue.</li>


                <li>
                  <p>For each constraint key-value pair in the "mandatory"
                  dictionary,</p>


                  <ol>
                    <li>
                      <p>If the constraint is not supported by the browser,
                      jump to the step labeled <em>Constraint Failure</em>
                      below.</p>
                    </li>


                    <li>
                      <p>Remove from the <var>candidateSet</var> any track that
                      cannot satisfy the value given for the constraint.</p>
                    </li>


                    <li>
                      <p>If the <var>candidateSet</var> no longer contains at
                      least one track, jump to the step labeled <em>Constraint
                      Failure</em> below. Otherwise, continue with the next
                      mandatory constraint.</p>
                    </li>
                  </ol>
                </li>


                <li>
                  <p>Let the <var>secondPassSet</var> be the current contents
                  of the <var>candidateSet</var>.</p>
                </li>


                <li>
                  <p>For each constraint key-value pair in the "optional"
                  sequence of the <var>constraints</var> that are for the
                  current media type, in order,</p>


                  <ol>
                    <li>
                      <p>If the constraint is not supported by the browser,
                      skip it and continue with the next constraint.</p>
                    </li>


                    <li>
                      <p>Remove from the <var>secondPassSet</var> any tracks
                      that cannot satisfy the value given for the
                      constraint.</p>
                    </li>


                    <li>
                      <p>If the <var>secondPassSet</var> is now empty, let the
                      <var>secondPassSet</var> be the current contents of the
                      <var>candidateSet</var>. Otherwise, let the
                      <var>candidateSet</var> be the current contents of the
                      <var>secondPassSet</var>.</p>
                    </li>
                  </ol>
                </li>


                <li>
                  <p><em>Final:</em> Add the tracks in the
                  <var>candidateSet</var> to the <var>finalSet</var>.</p>
                </li>
              </ol>
            </li>


            <li>
              <p>Return, and run the remaining steps asynchronously.</p>
            </li>


            <li>
              <p>Optionally, e.g., based on a previously-established user
              preference, for security reasons, or due to platform limitations,
              jump to the step labeled <em>Permission Failure</em> below.</p>
            </li>


            <li>
              <p>Prompt the user in a user agent specific manner for permission
              to provide the entry script's origin with a
              <code><a>MediaStream</a></code> object representing a media
              stream.</p>


              <p>The provided media MUST include precisely one track of each
              media type in requestedMediaTypes from the <var>finalSet</var>.
              The decision of which tracks to choose from the
              <var>finalSet</var> is completely up to the user agent and may be
              determined by asking the user. Once selected, the source of a
              <code><a>MediaStreamTrack</a></code> MUST not change.</p>


              <p class="issue">Define the event that should be raised when the
              user agent changes its choice of track.</p>


              <p>User agents are encouraged to default to using the user's
              primary or system default camera and/or microphone (when
              possible) to generate the media stream. User agents MAY allow
              users to use any media source, including pre-recorded media
              files.</p>


              <p>If the user grants permission to use local recording devices,
              user agents are encouraged to include a prominent indicator that
              the devices are "hot" (i.e. an "on-air" or "recording"
              indicator).</p>


              <p>If the user denies permission, jump to the step labeled
              <em>Constraint Failure</em> below. If the user never responds,
              this algorithm stalls on this step.</p>
            </li>


            <li>
              <p>Let <var>stream</var> be the <code><a>MediaStream</a></code>
              object for which the user granted permission.</p>
            </li>


            <li>
              <p>Queue a task to invoke <var>successCallback</var> with
              <var>stream</var> as its argument.</p>
            </li>


            <li>
              <p>Abort these steps.</p>
            </li>


            <li>
              <p><em>Permission Failure</em>: Let <var>error</var> be a new
              <code><a>MediaError</a></code> object whose
              <code><a>name</a></code> attribute has the value
              <code>PermissionDeniedError</code> and jump to the step labeled
              <em>Error Task</em> below.</p>
            </li>


            <li>
              <p><em>Constraint Failure</em>: Let <var>error</var> be a new
              <code><a>MediaError</a></code> object whose
              <code><a>name</a></code> attribute has the value
              <code>ConstraintNotSatisfiedError</code> and whose <code><a href=
              "#widl-MediaError-constraintName">constraintName</a></code>
              attribute is set to the name of the constraint that caused the
              error.</p>
            </li>


            <li>
              <p><em>Error Task:</em> Queue a task to invoke
              <var>errorCallback</var> with <var>error</var> as its
              argument.</p>
            </li>


            <li style="list-style: none; display: inline">
              <p>The task source for these <span title=
              "concept-task">tasks</span> is the user interaction task
              source.</p>
            </li>
          </ol>
        </dd>
      </dl>
    </section>


    <section>
      <h2>MediaStreamConstraints</h2>


      <p>The <code>MediaStreamConstraints</code> dictionary is used to instruct
      the UA what sort of <a>MediaStreamTrack</a>s to include in the
      <a>MediaStream</a> returned by <a>getUserMedia()</a>.</p>


      <dl class="idl" title="dictionary MediaStreamConstraints">
        <!--        <dt>boolean audio</dt>

        <dd>Set to true if an audio track is requested, default is false</dd>

        <dt>boolean video</dt>

        <dd>Set to true if a video track is requested, default is false</dd>
-->


        <dt>(boolean or Constraints) video = false</dt>


        <dd>
          <p>If <code>true</code>, it requests that the returned
          <a>MediaStream</a> contain a video track. If a <a>Constraints</a>
          structure is provided, it further specifies the nature and settings
          of the video Track. If <code>false</code>, the <a>MediaStream</a>
          MUST not contain a video Track.</p>
        </dd>


        <dt>(boolean or Constraints) audio = false</dt>


        <dd>
          <p>If <code>true</code>, it requests that the returned
          <a>MediaStream</a> contain an audio track. If a <a>Constraints</a>
          structure is provided, it further specifies the nature and settings
          of the audio Track. If <code>false</code>, the <a>MediaStream</a>
          MUST not contain an audio Track.</p>
        </dd>
      </dl>
    </section>


    <section>
      <h2>NavigatorUserMediaSuccessCallback</h2>


      <dl class="idl" title=
      "callback NavigatorUserMediaSuccessCallback = void">
        <dt>MediaStream stream</dt>


        <dd>
          <p class="issue">Add explanation of handleEvent</p>
        </dd>
      </dl>
    </section>


    <section>
      <h2>NavigatorUserMediaErrorCallback</h2>


      <dl class="idl" title="callback NavigatorUserMediaErrorCallback = void">
        <dt>MediaError error</dt>


        <dd>
          <p class="issue">Add explanation of handleEvent</p>
        </dd>
      </dl>
    </section>

      <section>
      <h2>Obtaining Screen Based Video</h2>


      <p> The video source does not have to be a camera, it can be some visible
      portion of the users screen. This is useful for varios screen sharing type
      applications. This section decries the API for an applications to indicate
      that it wishes to capture video from a canvas element, browser tab,
      application, or whole desktop. Browsers are not required to implement any
      of the elements described in this section to be WebRTC compliant
      implementation but this section describes an optional API that can be
      implement if appropriate for that device. There are significant security
      concerns with capture of the users screen as discussed in
      [[!RTCWEB-SECURITY-ARCH]] and [[!RTCWEB-SECURITY]]. Implementations need
      to ensure they do provide adequate security as discussed later in this
      section.  </p>

      <p> Capture of screen video is controlled by a new constraint called
      "mediaSource" which can take on the values "canvas", "tab", "window",
      "application", or "screen". This constraint can be passed to the
      <code><a>getUserMedia</a></code> call which can display a dialog that
      allows the user to select the correct input as well as gather appropriate
      permissions from the user. Typically the dialog would display show a list
      of thumbnails of the video sources that were available and allow users to
      pick the appropriate one. </p>

      <p> The video generated MUST be from the portion of the screen belonging
      to the item that was authorized and it MUST be visible. So if an
      application is being shared, but the top right corner of the application
      is covered by a window from some other application, that top right corner
      needs to be replaced with grey in the video stream.  </p>
      
      <section>
      <h3> Screen Based Video Constraints </h3>

      <p class="note"> Open Issue: This is described as a constraint but it may get moved to
      a setting. </p>

        <table class="simple">
        <thead>
          <tr>
            <th>Property Name</th>

            <th>Values</th>

            <th>Notes</th>
          </tr>
        </thead>

        <tbody>
             <tr id="def-constraint-mediaSource">
            <td><dfn>mediaSource</dfn>
            </td>

            <td><code><a>MediaSourceEnum</a></code>
            </td>

            <td>The source of the video from the users screen. </td>
          </tr>
        </tbody>
      </table>

        <dl class="idl" title="enum MediaSourceEnum">

        <dt>canvas</dt>
        <dd>The source is a selected HTML canvas element.</dd>

        <dt>tab</dt>
        <dd>The source is a tab in the same browsers.</dd>

        <dt>window</dt>
        <dd>The source is a window in some application.</dd>

        <dt>application</dt>
        <dd>The source is all the windows for some application.</dd>

         <dt>screen</dt>
        <dd>The source is the whole screen of one of the users monitors.</dd>
      </dl>

      <p> The choice of source elements presented to the user for selection can
      further be restricted by the additional constraints. </p>

        <table class="simple">
        <thead>
          <tr>
            <th>Property Name</th>

            <th>Values</th>

            <th>Notes</th>
          </tr>
        </thead>

        <tbody>

               <tr id="def-constraint-tabId">
            <td><dfn>tabId</dfn>
            </td>

            <td><code><a>long</a></code>
            </td>

            <td> Identifier that specifies which tab to capture. </td>
          </tr>

               <tr id="def-constraint-canvasId">
            <td><dfn>canvasId</dfn>
            </td>

            <td><code><a>long</a></code>
            </td>

            <td> Identifier that specifies which canvas element to capture. </td>
          </tr>
          
        </tbody>
      </table>
      
      </section>

        <section>
      <h3> Security and Permissions </h3>
  
      <p> There are several security issues that need to be considered including
      the issue of an "evil" web page requesting sharing of some tab then the
      "evil" page managing to open another web page, such as a banking page,
      inside that tab. The "evil" web page could then see information displayed
      on the banking page. These attacks and others are described in more
      detail in [[!RTCWEB-SECURITY]]. </p>

      <p> The approach to securing types of sharing where the webpage could
      impact the content is being shared is to require that web page
      have a persistent permission should some install user experience where there
      is a place to explain the risk to the user. The approach to sharing where
      this is not possible is to each time getUserMedia is called, offer the
      user a dialog where they choose the content they wish to share. This first
      type is refered to "Application Permission" and the second is referred to as
      "User Choice Permission". </p>

      <table class="simple">
        <thead>
          
          <tr>

            <th>Shared</th>

            <th>Permission</th>

          </tr>
          
        </thead>
        <tbody>
          
          <tr> <td> canvas </td> <td> Some canvas will allow getImageData to
            access the pixels in the canvas. These types of canvas do not need
            any additional permission. Other canvas requires Application
            Permission to use this and if a specific canvasId is not provided,
            they also needs User Choice Permission to select the tab.</td> </tr>
              
          <tr> <td> tab </td> <td> Requires Application Permission to use this
            and if a specific tabId is not provided, they also needs User Choice
            Permission to select the tab. </td> </tr>
              
          <tr> <td> window </td> <td> Needs User Choice Permission to select the
            window. </td> </tr>
              
          <tr> <td> application </td> <td> Needs User Choice Permission to
            select the application. </td> </tr>
              
          <tr> <td> screen </td> <td> Requires Application Permission to use
            this as well as the User Choice Permission to select the screen to
            share for multiscreen system and allow sharing to start for single
            screen systems.  </td> </tr>
              
        </tbody>
      </table>

      </section>


      </section>

    <section class="informative">
      <h2>Implementation Suggestions</h2>


      <div class="practice">
        <span id="resource-reservation" class="practicelab">Resource
        reservation</span>

        <p class="practicedesc">The user agent is encouraged to reserve
        resources when it has determined that a given call to <a href=
        "#dom-navigator-getusermedia">getUserMedia()</a> will succeed. It is
        preferable to reserve the resource prior to invoking the success
        callback provided by the web page. Subsequent calls to <a href=
        "#dom-navigator-getusermedia">getUserMedia()</a> (in this page or any
        other) should treat the resource that was previously allocated, as well
        as resources held by other applications, as busy. Resources marked as
        busy should not be provided as sources to the current web page, unless
        specified by the user. Optionally, the user agent may choose to provide
        a stream sourced from a busy source but only to a page whose origin
        matches the owner of the original stream that is keeping the source
        busy.</p>


        <p class="practicedesc">This document recommends that in the permission
        grant dialog or device selection interace (if one is present), the user
        be allowed to select any available hardware as a source for the stream
        requested by the page (provided the resource is able to fulfill
        mandatory constraints, if any were specified), in addition to the
        ability to substitute a video or audio source with local files and
        other media. A file picker may be used to provide this functionality to
        the user.</p>


        <p class="practicedesc">This document also recommends that the user be
        shown all resources that are currently busy as a result of prior calls
        to <a href="#dom-navigator-getusermedia">getUserMedia()</a> (in this
        page or any other page that is still alive) and be allowed to terminate
        that stream and utilize the resource for the current page instead. If
        possible in the current operating environment, it is also suggested
        that resources currently held by other applications be presented and
        treated in the same manner. If the user chooses this option, the track
        corresponding to the resource that was provided to the page whose
        stream was affected must be removed.</p>
      </div>


      <div class="practice">
        <span id="handling-devices" class="practicelab">Handling multiple
        devices</span>

        <p class="practicedesc">A <a>MediaStream</a> may contain more than one
        video and audio track. This makes it possible to include video from two
        or more webcams in a single stream object, for example. However, the
        current API does not allow a page to express a need for multiple video
        streams from independent sources.</p>


        <p class="practicedesc">It is recommended for multiple calls to
        <a href="#dom-navigator-getusermedia">getUserMedia()</a> from the same
        page be allowed as a way for pages to request multiple, discrete, video
        or audio streams.</p>


        <p class="practicedesc">A single call to <a href=
        "#dom-navigator-getusermedia">getUserMedia()</a> will always return a
        stream with either zero or one audio tracks, and either zero or one
        video tracks. If a script calls <a href=
        "#dom-navigator-getusermedia">getUserMedia()</a> multiple times before
        reaching a stable state, this document advises the UI designer that the
        permission dialogs should be merged, so that the user can give
        permission for the use of multiple cameras and/or media sources in one
        dialog interaction. The constraints on each getUserMedia call can be
        used to decide which stream gets which media sources.</p>
      </div>
    </section>
  </section>


  <section id="constrainable-interface">
    <h2>Constrainable Interface</h2>


    <p>The Constrainable interface allows its consumers to inspect and adjust
    the properties of the object that implements it. It is broken out as a
    separate interface so that it can be used in other specifications. The core
    concept is that of a Capability, which consists of a property or feature of
    an object and the set of its possible values, which may be specified either
    as a range or as an enumeration. For example, a camera might be capable of
    framerates (a property) between 20 and 50 frames per second (a range) and
    may be able to be positioned (a property) facing towards the user, away
    from the user, or to the left or right of the user (an enumerated set.) The
    application can examine a Constrainable object's set of Capabilities via
    the <code>getCapabilities()</code> accessor.</p>


    <p>The application can select the (range of) values it wants for an
    object's Capabilities by means of one or more ConstraintSets and the
    <code>applyConstraints()</code> method. A ConstraintSet consists of the
    names of one or more properties of the object plus the desired value (or a
    range of desired values) for each of them. Each of those property/value
    pairs can be considered to be an individual constraint. For example, the
    application may set a ConstraintSet containing two constraints, the first
    stating that the framerate of a camera be between 30 and 40 frames per
    second (a range) and the second that the camera should be facing the user
    (a specific value). ConstraintSets can be mandatory or optional. In the
    case of optional ConstraintSets, the UA will consider the ConstraintSets in
    the order in which they are specified, and will try to satisfy each one,
    but will ignore a ConstraintSet if it cannot satisfy it. In the case of a
    mandatory ConstraintSet, the UA will try to satisfy it, and will call the
    <code>errorCallback</code> if it cannot do so. For example, suppose that an
    application applies three individual constraints, one stating that the
    video aspect ratio should be 3 to 2 (height to width), the next that the
    height should be 600 and the last that the width should be 500. Since these
    constraints interact with each other (the aspect ratio affects the possible
    values for height and width, and vice-versa) it is impossible to satisfy
    all three of them, so if they are all contained in a mandatory
    ConstraintSet, the UA will call the <code>errorCallback</code>. However if
    any one of the constraints is placed in an optional ConstraintSet, the
    other two can be satisfied, so the UA will satisfy the two mandatory ones,
    silently ignore the optional one, and call the
    <code>successCallback.</code></p>


    <p>The ordering of optional ConstraintSets is significant. In the example
    in the previous paragraph, suppose that aspect ratio constraint is part of
    a mandatory ConstraintSet and that the height and width constraints are
    part of separate optional ConstraintSets. If the height ConstraintSet is
    specified first (and the other constraints in the ConstraintSet can also be
    satisfied), then it will be satisfied and the width ConstraintSet will be
    ignored. Thus the height will be set to 600 and the the width will be set
    to 400. On the other hand, if width is specified before height, the width
    ConstraintSet will be satisfied and the height ConstraintSet will be
    ignored, resulting in width of 500 and height of 750. (Note that the
    mandatory aspect ratio constraint is enforced in both cases.) The UA will
    attempt to satisfy as many optional ConstraintSets as it can, even if some
    of them cannot be satisfied and must therefore be ignored. Application
    authors can therefore implement a backoff strategy by specifying multiple
    optional ConstraintSets for the same property. For example, an application
    might specify three optional ConstraintSets, the first asking for a
    framerate greater than 500, the second asking for a framerate greater than
    400, and the third asking for one greater than 300. If the UA is capable of
    setting a framerate greater than 500, it will (and the subsequent two
    ConstraintSets will be trivially satisfied.) However, if the UA cannot set
    the framerate above 500, it will ignore that ConstraintSet and attempt to
    set the framerate above 400. If that fails, it will then try to set it
    above 300. If the UA cannot satisfy any of the three ConstraintSets, it
    will set the framerate to any value it can get. If the developer wanted to
    insist on 300 as a lower bound, he put that in a mandatory ConstraintSet.
    In that case, the UA would fail altogether if it couldn't get a value over
    300, but would choose a value over 500 if possible, then try for a value
    over 400. An application may inspect the set of ConstraintSets currently in
    effect via the <code>getConstraints()</code> accessor.</p>


    <p>The specific value that the UA chooses for a Capability is referred to
    as a Setting. For example, if the application applies a ConstraintSet
    specifying that the framerate must be at least 30 frames per second, and no
    greater than 40, the Setting can be any intermediate value, e.g., 32, 35,
    or 37 frames per second. The application can query the current settings of
    the object's Capabilities via the <code><a>getSettings()</a></code>
    accessor.</p>


    <section>
      <h2>Interface Definition</h2>


      <dl class="idl" title="[NoInterfaceObject] interface Constrainable">
        <dt>Capabilities getCapabilities()</dt>


        <dd>
          <p>The <dfn>getCapabilities()</dfn> method returns the dictionary of
          the capabilities that the object supports.</p>


          <div class="note">
            <p>It is possible that the underlying hardware may not exactly map
            to the range defined in the registry entry. Where this is possible,
            the entry <em title="should" class="rfc2119">should</em> define how
            to translate and scale the hardware's setting onto the values
            defined in the entry. For example, suppose that a registry entry
            defines a hypothetical fluxCapacitance capability that is defined
            to be the range from -10 (min) to 10 (max), but there are common
            hardware devices that support only values of "off" "medium" and
            "full". The registry entry might specify that for such hardware,
            the user agent should map the range value of -10 to "off", 10 to
            "full", and 0 to "medium". It might also indicate that given a
            ConstraintSet imposing a strict value of 3, the user agent should
            attempt to set the value of "medium" on the hardware, and and that
            <code><a>getSettings()</a></code> should return a fluxCapacitance
            of 0, since that is the value defined as corresponding to
            "medium".</p>
          </div>
        </dd>


        <dt>Constraints getConstraints()</dt>


        <dd>
          <p>The <dfn>getConstraints()</dfn> method returns all the
          <code>ConstraintSets</code> that were applied to the object in the
          last successful call of <code>applyConstraints()</code>. The value
          <em title="must" class="rfc2119">must</em> contain only the
          ConstraintSets that were successfully applied, and it <em title=
          "must" class="rfc2119">must</em> maintain the order that they were
          specified in.</p>


          <p>If no mandatory ConstraintSet has been defined, the
          <code>mandatory</code> field will not be present (it will be
          undefined). If no optional ConstraintSets have been defined, the
          <code>optional</code> field will not be present (it will be
          undefined). If neither optional nor mandatory ConstraintSets have
          been created, the value will be <code>null</code>.</p>


        </dd>


        <dt>Settings getSettings()</dt>


        <dd>The <dfn>getSettings()</dfn> method returns the current settings of
        all the properties of the object, whether they are platform defaults or
        have been set by <code>applyConstraints()</code>. Note that the actual
        setting of a property <em title="must" class="rfc2119">must</em> be a
        single value.</dd>


        <dt>void applyConstraints()</dt>


        <dd>
          <dl class="parameters">
            <dt>Constraints constraints</dt>


            <dd>A new constraint structure to apply to this object.</dd>


            <dt>VoidFunction successCallback</dt>


            <dd>Called if the mandatory ConstraintSet can be satisfied.</dd>


            <dt>ConstraintErrorCallback errorCallback</dt>


            <dd>Called if the mandatory ConstraintSet cannot be satisfied.</dd>
          </dl>


          <p>The <dfn>applyConstraints()</dfn> algorithm for applying
          constraints is stated below. Here are some preliminary definitions
          that are used in the statement of the algorithm:</p>


          <ul>
            <li>We refer to each property/value pair in a ConstraintSet as a
            'constraint' (since it is intended to constrain the corresponding
            Capability of the Constrainable object to a value that is within
            the range or list of values it specifies.)</li>


            <li>A set of values for the properties of an object O satisfy
            ConstraintSet C if each value a) is in the set of supported values
            specified by the corresponding Capability of O, and b) is in the
            range or list of values specified by the constraint in C that
            applies to that property, if there is one, and c) there is no
            constraint in C that does not correspond to a Capability in O.
            (Note that although this definition ignores the difference between
            mandatory and optional ConstraintSets, the algorithm below
            distinguishes between them.)</li>


            <li>A ConstraintSet C can be satisfied by an object O if it is
            possible to choose a sequence of values for the properties of O
            that satisfy C.</li>


            <li>To apply a set of ConstraintSet C to object O is to choose such
            a sequence of values that satisfy C and assign them as the settings
            for the properties of O.</li>
          </ul>


          <p>When <code>applyConstraints</code> is called, the UA <em title=
          "must" class="rfc2119">must</em> queue a task to run the following
          steps:</p>


          <ol>
            <li>let <var>desiredContraints</var> be the argument to this
            function. Each constraint <em title="must" class=
            "rfc2119">must</em> specify one or more values (or a range of
            values) for its property. A property <em title="may" class=
            "rfc2119">may</em> appear more than once in the list of optional
            ConstraintSets.</li>


            <li>Let <var>newConstraints</var> be an initially 
            	empty Constraints dictionary.  Let <var>existingConstraints</var>
            	be the Constraints currently in effect (i.e. what is returned by
            	<code>getConstraints</code>.)</li>


            <li>Let <var>object</var> be the Constrainable object on which this
            method was called. Let <var>copy</var> be an unconstrained copy of
            <var>object</var> (i.e., <var>copy</var> should behave as if it
            were <var>object</var> with all ConstraintSets removed.)</li>


            <li>If the mandatory ConstraintSet in <var>desiredConstraints</var> is
            	non-null and
            cannot be satisfied by <var>copy</var>, call the
            <code>errorCallback</code>, passing it a new
            <code>MediaError</code> with name
            <code>ConstraintNotSatisfied</code> and <code>constraintName</code>
            set to any of the mandatory constraints that could not be
            satisfied, and return. <var>existingConstraints</var> remain in
            effect in this case.</li>


            <li>Otherwise if the mandatory ConstraintSet is non-null, set
            	it as the value of the 'mandatory' element in
            <var>newConstraints</var></li>


            <li>Iterate over the optional ConstraintSets in
            <var>desiredConstraints</var> in the order in which they were
            specified. For each ConstraintSet,if it and
            <var>newConstraints</var> together can be satisfied by
            <var>copy</var>, append it to the value of the 'optional' element in <var>newConstraints</var>. Otherwise,
            ignore it.</li>


            <li>In a single operation, remove <var>existingConstraints</var> from
            <var>object</var>, apply <var>newConstraints</var>, and fire the
            <code>successCallback</code>. From this point on until applyConstraints() is
            called successfully again, getConstraints() <em title="must" class=
            "rfc2119">must</em> return <var>newConstraints</var>. Note: the UA
            MAY modify the values of one or more properties of
            <var>object</var> at any time, as long as the resulting set of
            values satisfy the current set of constraints.</li>
          </ol>
        </dd>


        <dt>attribute EventHandler onoverconstrained</dt>


        <dd>This event handler, of type <code><a href=
        "#event-constrainable-overconstrained">overconstrained</a></code>,
        <em title="must" class="rfc2119">must</em> be supported by all objects
        implementing the <code><a>Constrainable</a></code> interface.  
        
          <p>The UA <em title="must" class="rfc2119">must</em> raise a
          <code>MediaErrorEvent</code> named "overconstrained" if changing
          circumstances at runtime result in the currently valid mandatory
          ConstraintSet no longer being satisfied. This MediaErrorEvent
          <em title="must" class="rfc2119">must</em> contain a MediaError whose
          <code>name</code> is "overconstrainedError", and whose
          <code>constraintName</code> attribute is set to one of the mandatory
          constraints that can no longer be satisfied. The <code>message</code>
          attribute of the MediaError SHOULD contain a string that is useful
          for debugging. The conditions under which this error might occur are
          platform and application-specific. For example, the user might
          physically manipulate a camera in a way that makes it impossible to
          provide a resolution that satisfies the constraints. The UA MAY take
          other actions as a result of the overconstrained situation.</p></dd>
      </dl>


      <section>
        <h3>applyConstraints Failure Callback</h3>


        <section>
          <section>
            <h4>ConstraintErrorCallback</h4>


            <dl class="idl" title="callback ConstraintErrorCallback = void">
              <dt>MediaError error</dt>


              <dd>An <code>MediaError</code> holding the mandatory constraint
              that could not be satisfied.</dd>
            </dl>
          </section>
        </section>
      </section>


      <p>An example of Constraints that could be passed into
      <code><a>applyConstraints()</a></code> or returned as a value of
      <code><a>constraints</a></code> is below. It uses the properties defined
      in <a href="#sec-track-properties">the Track property registry</a>.</p>

      <pre xml:space="preserve" class="example highlight">
{
  "mandatory": {
    "width": {
      "min": 640
    },
    "height": {
      "min": 480
    }
  },
  "optional": [{
    "width": 650
  }, {
    "width": {
      "min": 650
    }
  }, {
    "frameRate": 60
  }, {
    "width": {
      "max": 800
    }
  }, {
    "facingMode": "user"
  }]
}                             
</pre>
    </section>


    <section id="registry">
      <h2>The Property Registry</h2>


      <p>For each class/interface that implements Constrainable, there
      <em title="must" class="rfc2119">must</em> be a corresponding registry
      that defines the constrainable properties of that class of object. The
      registry entries <em title="must" class="rfc2119">must</em> contain the
      name of each property along with its set of legal values. The registry
      for MediaStreamTrack is defined <a href="#sec-constraints">below</a>. The
      syntax for the specification of the set of legal values depends on the
      type of the values. <!-- TODO - CJ - next sense seems wrong -->
       In addition to the standard atomic types (boolean, long, float,
      DOMString), legal values include lists of any of the atomic types, plus
      min-max ranges, as defined below.</p>


      <p>List values <em title="must" class="rfc2119">must</em> be interpreted
      as disjunctions. For example, if a property 'facingMode' for a camera is
      defined as having legal values ["left", "right", "user", "environment"],
      this means that 'facingMode' can have the value "left", the value
      "right", the value "environment" or the value "user". Similarly
      <a>Constraints</a> restricting 'facingMode' to ["user", "left", "right"]
      would mean that the UA should select a camera (or point the camera, if
      that is possible) so that "facingMode" is either "user", "left", or
      "right". This Constraint would thus request that the camera not be facing
      away from the user, but would allow the UA to choose among the other
      directions.</p>


      <section id="PropertyValueSet">
        <h3><dfn>PropertyValueSet</dfn>
        </h3>


        <dl class="idl" title="typedef PropertyValueSet DOMString[]">
        </dl>
      </section>


      <section id="PropertyValueDoubleRange">
        <h3>PropertyValueDoubleRange</h3>


        <dl class="idl" title="dictionary PropertyValueDoubleRange">
          <dt>double max</dt>


          <dd>The maximum legal value of this property.</dd>


          <dt>double min</dt>


          <dd>The minimum value of this Property.</dd>
        </dl>
      </section>


      <section id="PropertyValueLongRange">
        <h3>PropertyValueLongRange</h3>


        <dl class="idl" title="dictionary PropertyValueLongRange">
          <dt>long max</dt>


          <dd>The maximum legal value of this property.</dd>


          <dt>long min</dt>


          <dd>The minimum value of this Property.</dd>
        </dl>
      </section>
    </section>


    <section id="capabilities">
      <h3>Capabilities</h3>


      <p><dfn>Capabilities</dfn> are dictionary containing one or more
      key-value pairs, where each key <em title="must" class=
      "rfc2119">must</em> be a constrainable property defined in the associated
      registry, and each value <em title="should" class="rfc2119">must</em> be
      a subset of the set of values defined for that property in the registry.
      The exact syntax of the value expression depends on the type of the
      property but is of type <code><a>ConstraintValues</a></code>. The
      Capabilities dictionary specifies the subset of the constrainable
      properties and values from the registry that the UA supports. Note that a
      UA <em title="may" class="rfc2119">may</em> support only a subset of the
      properties that are defined in the registry, and <em title="may" class=
      "rfc2119">may</em> support a subset of the set values for those
      properties that it does support. Note that Capabilities are returned from
      the UA to the application, and cannot be specified by the application.
      However, the application can control the Settings that the UA chooses for
      Capabilities by means of ConstraintSets.</p>


      <p>An example of a Capabilities dictionary is shown below. This example
      is not very realistic in that a browser would actually be required to
      support more settings that just these.</p>

      <pre xml:space="preserve" class="example highlight">
{
  "frameRate": {
    "min": 1.0,
    "max": 60.0
  },
  "facingMode": ["user", "environment"]
}                         
</pre>
    </section>


    <section id="settings">
      <h3><dfn>Settings</dfn>
      </h3>


      <p>A <dfn>Setting</dfn> is a dictionary containing one or more key-value
      pairs. It <em title="must" class="rfc2119">must</em> contain each key
      returned in <code>getCapabilities()</code>. There <em title="must" class=
      "rfc2119">must</em> be a single value for each key and the value
      <em title="must" class="rfc2119">must</em> a member of the set defined
      for that property by <code>capabilities()</code>. The exact syntax of the
      value expression depends on the type of the property. It will be a
      DomString for properties of type PropertyValueSet, it will be a long for
      properties of type PropertyValueLongRange , it will be a double for
      properties of type PropertyValueDoubleRange. Thus the
      <code>Settings</code> dictionary contains the actual values that the UA
      has chosen for the object's Capabilities.</p>


      <p>An example of a Setting dictionary is shown below. This example is not
      very realistic in that a browser would actually be required to support
      more settings that just these.</p>

      <pre xml:space="preserve" class="example highlight">
{
  "frameRate": 30.0,
  "facingMode": "user"
}
</pre>
    </section>


    <section id="constraints">
      <h3><dfn>Constraints</dfn>
      </h3>


      <dl class="idl" title="dictionary Constraints">
        <dt>
          <a href="#constraintset">ConstraintSet?</a> mandatory
        </dt>


        <dd>
          <p>The set of constraints that the UA <em title="must" class=
          "rfc2119">must</em> satisfy or else call the
          <code>errorCallback</code>.</p>
        </dd>


        <dt>ConstraintSet[] optional</dt>


        <dd>
          <p>The set of ConstraintSets that the UA <em title="should" class=
          "rfc2119">should</em> try to satisfy but <em title="may" class=
          "rfc2119">may</em> ignore if they cannot be satisfied. The order of
          these ConstraintSets is significant. In particular, when they are
          passed as an argument to <code>applyConstraints</code>, the UA
          <em title="must" class="rfc2119">must</em> try to satisfy them in the
          order that is specified. Thus if optional ConstraintSets C1 and C2
          can be satisfied individually, but not together, then whichever of C1
          and C2 is first in this list will be satisfied, and the other will
          not. The UA <em title="must" class="rfc2119">must</em> attempt to
          satisfy all optional ConstraintSets in the list, even if some cannot
          be satisfied. Thus, in the preceding example, if optional constraint
          C3 is specified after C1 and C2, the UA will attempt to satisfy C3
          even though C2 cannot be satisfied. Note that a given property name
          may occur multiple times in these sets.</p>
        </dd>
      </dl>


      <p>Each property of a <a href="constraintset">ConstraintSet</a>
      corresponds to a Capability and specifies a subset of its legal values.
      Applying a ConstraintSet instructs that UA to restrict the setting of the
      corresponding Capabilities to the specified values or ranges of values. A
      given property MAY occur both in the mandatory and the optional
      ConstraintSets list, and MAY occur more than once in the optional
      ConstraintSets list.</p>


      <section id="constraintset">
        <h4>ConstraintSet</h4>


        <div class="note">
          Open Issue: Do we need to add support for a boolean type in
          constraints? Is the ConstraintValue below an OK addition which will
          allow constraints like { width: 66 } as a short hand for min=max=66. 
        </div>

     <dl class="idl" title=

          "typedef (DOMString or long or double or boolean) ConstraintValue">

        </dl>
        
        <dl class="idl" title=
          
        "typedef (ConstraintValue or PropertyValueSet or PropertyValueLongRange or PropertyValueDoubleRange) ConstraintValues">

        </dl>


        <dl class="idl" title="[NoInterfaceObject] interface ConstraintSet">
          <dt> ConstraintValues getter(DOMString name)</dt>


          <dd>The property represents the name of the constraint, which
          correspond to a Capability of the Constrainable object. The value of
          the property represents the desired range of values for the
          Capability.</dd>
        </dl>


        <p>In ECMAScript, ConstraintSet objects are represented using regular
        native objects with optional properties whose names represent
        constraint name. The conversion from an ECMAScript value, representing
        a ConstraintSet, to an IDL ConstraintSet <em title="must" class=
        "rfc2119">must not</em> fail if a property name in the ECMAScript value
        does not match any of the Capabilities of the Constrainable object.</p>


        <p>In ECMAScript, all the properties of the ConstraintSet object are
        optional; the developer may specify any of these properties when
        creating the object. Note, however, that unknown property names will
        result in a ConstraintSet that can not be satisfied, as described in
        <code><a>applyConstraints()</a></code> above.</p>
      </section>
    </section>
  </section>


  <section>
    <h2>Examples</h2>


    <div>
      <p>This sample code exposes a button. When clicked, the button is
      disabled and the user is prompted to offer a stream. The user can cause
      the button to be re-enabled by providing a stream (e.g., giving the page
      access to the local camera) and then disabling the stream (e.g., revoking
      that access).</p>

      <pre xml:space="preserve" class="example highlight">
&lt;input type="button" value="Start" onclick="start()" id="startBtn"&gt;
&lt;script&gt;
 var startBtn = document.getElementById('startBtn');

 function start() {
     navigator.getUserMedia({
         audio: true,
         video: true
     }, gotStream, logError);
     startBtn.disabled = true;
 }

 function gotStream(stream) {
     stream.oninactive = function () {
         startBtn.disabled = false;
     };
 }

 function logError(error) {
     log(error.name + ": " + error.message);
 }
&lt;/script&gt; 
</pre>
    </div>
    <!-- Put back when we define MediaStreamRecorder
    <div>
      
      <p>This example allows people to record a short audio message and upload
      it to the server. This example even shows rudimentary error handling.</p>
      
      <pre xml:space="preserve" class="example highlight">
&lt;input type="button" value="Start" onclick="msgRecord()" id="recBtn"&gt;
&lt;input type="button" value="Stop" onclick="msgStop()" id="stopBtn" disabled&gt;
&lt;p id="status"&gt;To start recording, press the Start button.&lt;/p&gt;
&lt;script&gt;
 var recBtn = document.getElementById('recBtn');
 var stopBtn = document.getElementById('stopBtn');

 function report(s) {
     document.getElementById('status').textContent = s;
 }

 function msgRecord() {
     report('Attempting to access microphone...');
     navigator.getUserMedia({
         audio: true
     }, gotStream, noStream);
     recBtn.disabled = true;
 }
 var msgStream, msgStreamRecorder;

 function gotStream(stream) {
     report('Recording... To stop, press the Stop button.');
     msgStream = stream;
     msgStreamRecorder = stream.record();
     stopBtn.disabled = false;
     stream.oninactive = function () {
         msgStop();
     }
 }

 function msgStop() {
     report('Creating file...');
     stopBtn.disabled = true;
     msgStream.oninactive = null;
     msgStream.stop();
     msgStreamRecorder.getRecordedData(msgSave);
 }

 function msgSave(blob) {
     report('Uploading file...');
     var x = new XMLHttpRequest();
     x.open('POST', 'uploadMessage');
     x.send(blob);
     x.onload = function () {
         report('Done! To record a new message, press the Start button.');
         recBtn.disabled = false;
     };
     x.onerror = function () {
         report('Failed to upload message. To try recording a message again, press the Start button.');
         recBtn.disabled = false;
     };
 }

 function noStream() {
     report('Could not obtain access to your microphone. To try again, press the Start button.');
     recBtn.disabled = false;
 }
&lt;/script&gt;
</pre>
    </div>-->


    <div>
      <p>This example allows people to take photos of themselves from the local
      video camera. Note that the forthcoming Image Capture specification may
      provide a simpler way to accomplish this.</p>

      <pre xml:space="preserve" class="example highlight">
&lt;article&gt;
 &lt;style scoped&gt;
  video { transform: scaleX(-1); }
  p { text-align: center; }
 &lt;/style&gt;
 &lt;h1&gt;Snapshot Kiosk&lt;/h1&gt;
 &lt;section id="splash"&gt;
  &lt;p id="errorMessage"&gt;Loading...&lt;/p&gt;
 &lt;/section&gt;
 &lt;section id="app" hidden&gt;
  &lt;p&gt;&lt;video id="monitor" autoplay&gt;&lt;/video&gt; &lt;canvas id="photo"&gt;&lt;/canvas&gt;
  &lt;p&gt;&lt;input type=button value="&amp;#x1F4F7;" onclick="snapshot()"&gt;
 &lt;/section&gt;
 &lt;script&gt;
 navigator.getUserMedia({
     video: true
 }, gotStream, noStream);
 var video = document.getElementById('monitor');
 var canvas = document.getElementById('photo');

 function gotStream(stream) {
     video.srcObject = stream;
     stream.oninactive = noStream;
     video.onloadedmetadata = function () {
         canvas.width = video.videoWidth;
         canvas.height = video.videoHeight;
         document.getElementById('splash').hidden = true;
         document.getElementById('app').hidden = false;
     };
 }

 function noStream() {
     document.getElementById('errorMessage').textContent = 'No camera available.';
 }

 function snapshot() {
     canvas.getContext('2d').drawImage(video, 0, 0);
 }
 &lt;/script&gt;
&lt;/article&gt;
</pre>
    </div>
  </section>


  <section>
    <h1>Error Names</h1>


    <p>This specification defines the following new error names</p>


    <ul>
      <li>PermissionDeniedError: User denied permission for scripts from this
      origin to access the media device.</li>


      <li>ConstraintNotSatisfiedError: One of the mandatory constraints could
      not be satisfied.</li>


      <li>OverconstrainedError: Due to changes in the environment, one or more
      mandatory constraints can no longer be satisfied.</li>
    </ul>
  </section>


  <section>
    <h1 id="sec-iana">IANA Registrations</h1>


    <section>
      <h2 id="sec-track-properties">Track Property Registrations</h2>


      <p>IANA is requested to register the following properties as specified in
      [[!RTCWEB-CONSTRAINTS]]:</p>


      <div class="note">
        <p><strong>Note:</strong> The definitions for "noaccess" and
        "peerIdentity" are proposals under discussion, which may result in
        considerable modification. The other constraints listed are thought to
        be stable.</p>
      </div>


      <p>The following constraint names are defined to apply to both
      <code><a>VideoStreamTrack</a></code> and
      <code><a>AudioStreamTrack</a></code> objects:</p>


      <table class="simple">
        <thead>
          <tr>
            <th>Property Name</th>

            <th>Values</th>

            <th>Notes</th>
          </tr>
        </thead>


        <tbody>
          <tr id="def-constraint-sourceType">
            <td><dfn>sourceType</dfn>
            </td>

            <td>
              <a><code>SourceTypeEnum</code></a>
            </td>

            <td>
              the type of the source of the <a>MediaStreamTrack</a>.
            </td>
          </tr>


          <tr id="def-constraint-sourceId">
            <td><dfn>sourceId</dfn>
            </td>

            <td>DOMString</td>

            <td>The application-unique identifier for this source. The same
            identifier MUST be valid between sessions of this application, but
            MUST also be different for other applications. Some sort of GUID is
            recommended for the identifier.</td>
          </tr>


          <tr id="def-constraint-noaccess">
            <td><dfn>noaccess</dfn>
            </td>

            <td>boolean</td>

            <td>
              Whether the <a>MediaStreamTrack</a> can be applied to an element
              which is readable by the JS.
            </td>
          </tr>


          <tr id="def-constraint-peerIdentity">
            <td><dfn>peerIdentity</dfn>
            </td>

            <td>DOMString</td>

            <td>Whether the stream can applied to an element which is readable
            by the JS. Require that any PeerConnections to which the stream is
            added match the provided identity.</td>
          </tr>
        </tbody>
      </table>


      <p>The following properties are defined to apply only to
      <code><a>VideoStreamTrack</a></code> objects:</p>


      <table class="simple">
        <thead>
          <tr>
            <th>Property Name</th>

            <th>Values</th>

            <th>Notes</th>
          </tr>
        </thead>


        <tbody>
          <tr id="def-constraint-width">
            <td><dfn>width</dfn>
            </td>

            <td>
              <a><code>PropertyValueLongRange</code></a>
            </td>

            <td>The width or width range, in pixels, of the video source. As a
            capability, the range should span the video source's pre-set width
            values with min being the smallest width and max being the largest
            width.</td>
          </tr>


          <tr id="def-constraint-height">
            <td><dfn>height</dfn>
            </td>

            <td>
              <a><code>PropertyValueLongRange</code></a>
            </td>

            <td>The height or height range, in pixels, of the video source. As
            a capability, the range should span the video source's pre-set
            height values with min being the smallest height and max being the
            largest height.</td>
          </tr>


          <tr id="def-constraint-frameRate">
            <td><dfn>frameRate</dfn>
            </td>

            <td>
              <a><code>PropertyValueDoubleRange</code></a>
            </td>

            <td>The exact desired frame rate (frames per second) or frameRate
            range of the video source. If the source does not natively provide
            a frameRate, or the frameRate cannot be determined from the source
            stream, then this value MUST refer to the user agent's vsync
            display rate.</td>
          </tr>


          <tr id="def-constraint-aspect">
            <td><dfn>aspectRatio</dfn>
            </td>

            <td>
              <a><code>PropertyValueDoubleRange</code></a>
            </td>

            <td>The exact aspect ratio (width in pixels divided by height in
            pixels), represented as a double rounded to the tenth decimal
            place.</td>
          </tr>


          <tr id="def-constraint-facingMode">
            <td><dfn>facingMode</dfn>
            </td>

            <td><code><a>PropertyValueSet</a></code>
            </td>

            <td>The members of the enum describe the directions that the camera
            can face, as seen from the user's perspective. Valid values for the
            strings in the PropertyValueSet are the values of <code>enum
            VideoFacingModeEnum</code>.</td>
          </tr>
        </tbody>
      </table>


      <dl class="idl" title="enum VideoFacingModeEnum">
        <dt>user</dt>


        <dd>The source is facing toward the user (a self-view camera).</dd>


        <dt>environment</dt>


        <dd>The source is facing away from the user (viewing the
        environment).</dd>


        <dt>left</dt>


        <dd>The source is facing to the left of the user.</dd>


        <dt>right</dt>


        <dd>The source is facing to the right of the user.</dd>
      </dl>


      <p>Below is an illustration of the video facing modes in relation to the
      user.<br />
      <img alt="Illustration of video facing modes in relation to user" src=
      "images/camera-names-exp.svg" style="width:40%" /></p>


      <p>The following properties are defined to apply only to
      <code><a>AudioStreamTrack</a></code> objects:</p>


      <table class="simple">
        <thead>
          <tr>
            <th>Property Name</th>

            <th>Values</th>

            <th>Notes</th>
          </tr>
        </thead>


        <tbody>
          <tr id="def-constraint-volume">
            <td>volume</td>

            <td>
              <a><code>PropertyValueLongRange</code></a>
            </td>

            <td>The volume or volume range of the audio source, as a
            percentage. A volume of 0 is silence, while a volume of 100 is the
            maximum supported volume.</td>
          </tr>
        </tbody>
      </table>


      <div class="note">
        Open Issue: volume seems like better as double, or even better as
        double in dB. what value is it set at if one wants it half as loud?
      </div>


      <dl>
        <!-- please leaves this just commented out in the file for now - Cullen

      <dt> EchoCancelation </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "true". </p>

        <p> When one or more audio streams is being played in the proceses of
        varios microphones, it is often desirable to attempt to remove the sound
        being played from the input signals recorded by the microphones. This is
        referred to echo cancelation. There are cases where it is not needed and
        it is desirable to turn it off so that no audio artifacts are
        introduced. This constraint allows the application to control this
        behavior. </p>
      </dd>

      <dt> CaptureAudio </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "true". </p>

        <p> Indicates that application would like to capture audio input from a
        microphone. </p>
      </dd>

      <dt> CaptureVideo </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "true". </p>

        <p> Indicates that application would like to capture video input from a
        camera. </p>
      </dd>

      <dt> CaptureImage </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "true". </p>

        <p> Indicates that application would like to capture an single image from a
        camera. </p>
      </dd>


        <dt> EnableSecureMedia </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "false". </p>

        <p> Indicates that application would like the browser to keep the media
        secure. This means that the media will not be a available to JavaScript
        application but is useful for cases where other objects will operate on
        the media stream. For some trusted application environments, the browser
        may enforce that this constraint is a mandatory "true". </p> </dd>

      -->
      </dl>
    </section>
  </section>


  <section>
    <h2>Change Log</h2>


    <p>This section will be removed before publication.</p>


    <h2>Changes since December 25, 2013</h2>


    <ol>
      <li>Make optional constraints a list of ConstraintSets. Make
      ConstraintSet an object.</li>
    </ol>


    <h2>Changes since November 5, 2013</h2>


    <ol>
      <li>ACTION-25: Switch mediastream.inactive to mediastream.active.</li>


      <li>ACTION-26: Rewrite stop to only detach the track's source.</li>


      <li>Bug 22338: Arbitrary changing of tracks.</li>


      <li>Bug 23125: Use double rather than float.</li>


      <li>Bug 22712: VideoFacingMode enum needs an illustration.</li>


      <li>Moved constraints into a separate Constrainable interface.</li>


      <li>Created a separate section on error handling.</li>
    </ol>


    <h2>Changes since October 17, 2013</h2>


    <ol>
      <li>Bug 23263: Add output device enumeration to GetSources</li>


      <li>Introduced the Constrainable interface.</li>


      <li>Change consensus note on constraints in IANA section.</li>


      <li>Removed createObjectURL.</li>


      <li>Bug 22209: Should not use MUST requirements on values provided by the
      developer.</li>
    </ol>


    <h2>Changes since August 24, 2013</h2>


    <ol>
      <li>Bug 22269: Renamed getSourceInfos() to getSources() and made the
      result async.</li>


      <li>Bug 22229: Editorial input</li>


      <li>Bug 22243: Clarify readonly track</li>


      <li>Bug 22259: Disabled mediastreamtrack and state of media element</li>


      <li>Bug 22226: Remove check of same source from MediaStream constructor
      algorithm</li>


      <li>Replaced ended with inactive for MediaStream (resolves bug
      21618).</li>


      <li>Bug 22264: MediaStream.ended set to true on creation</li>


      <li>Bug 22272: Permission revocation via MediaStreamTrack.stop()</li>


      <li>Bug 22248: Relationship between MediaStreamTrack and HTML5
      VideoTrack/AudioTrack after MediaStream assignment</li>


      <li>Bug 22247: Setting loop attribute on a media element reading from a
      MediaStream</li>
    </ol>


    <h2>Changes since July 4, 2013</h2>


    <ol>
      <li>Bug 21967: Added paragraph on MediaStreamTrack enabled state and
      updated cloning algorithm.</li>


      <li>Bug 22210: Make getUserMedia() algorithm use all numbered items.</li>


      <li>Bug 22250: Fixed accidentally overridden error.</li>


      <li>Bug 22211: Added async error when no valid media type is
      requested.</li>


      <li>Bug 22216: Made NavigatorUserMediaError extend DOMError.</li>


      <li>Bug 22249: Throw on attempts to set currentTime on media elements
      playing MediaStream objects.</li>


      <li>Bug 22246: Made media.buffered have length 0.</li>


      <li>Bug 22692: Updated media element to use HAVE_NOTHING state before
      media arrives on the played MediaStream and HAVE_ENOUGH_DATA as soon as
      media arrives.</li>
      <!-- TODO FIX NO IDEA -->
    </ol>


    <h2>May 29, 2013</h2>


    <ol>
      <li>Bug 22252: fixed usage of MUST in MediaStream() constructor
      description.</li>


      <li>Bug 22215: made MediaStream.ended readonly.</li>


      <li>Bug 21967: clarified MediaStreamTrack.enabled state initial
      value.</li>


      <li>Added aspectRatio constraint, capability, and state.</li>


      <li>Updated usage of MediaStreams in media elements.</li>
    </ol>


    <h2>May 15, 2013</h2>


    <ol>
      <li>Added explanatory section for constraints, capabilities, and
      states.</li>


      <li>Added VideoFacingModeEnum (including left and right options).</li>


      <li>Added getSourceInfos() and SourceInfo dictionary.</li>


      <li>Added isolated streams.</li>
    </ol>


    <h2>April 29, 2013</h2>


    <ol>
      <li>Removed remaining photo APIs and references (since we have a separate
      Image Capture Spec).</li>
    </ol>


    <h2>March 20, 2013</h2>


    <ol>
      <li>Added readonly and remote attributes to MediaStreamTrack</li>


      <li>Removed getConstraint(), setConstraint(), appendConstraint(), and
      prependConstraint().</li>


      <li>Added source states. Added states() method on tracks. Moved
      sourceType and sourceId to be states.</li>


      <li>Added source capabilities. Added capabilities() method on
      tracks.</li>


      <li>Added clarifying text about MediaStreamTrack lifecycle and
      mediaflow.</li>


      <li>Made MediaStreamTrack cloning explicit.</li>


      <li>Removed takePhoto() and friends from VideoStreamTrack (we have a
      separate Image Capture Spec).</li>


      <li>Made getUserMedia() error callback mandatory.</li>
    </ol>


    <h2>December 12, 2012</h2>


    <ol>
      <li>Changed error code to be string instead of number.</li>


      <li>Added core of settings proposal allowing for constraint changes after
      stream/track creation.</li>
    </ol>


    <h2>November 15 2012</h2>


    <ol>
      <li>Introduced new representation of tracks in a stream (removed
      MediaStreamTrackList).</li>


      <li>Updated MediaStreamTrack.readyState to use an enum type (instad of
      unsigned short constants).</li>


      <li>Renamed MediaStream.label to MediaStream.id (the definition needs
      some more work).</li>
    </ol>


    <h2>October 1 2012</h2>


    <ol>
      <li>Limited the track kind values to "audio" and "video" only (could
      previously be user defined as well).</li>


      <li>Made MediaStream extend EventTarget.</li>


      <li>Simplified the MediaStream constructor.</li>
    </ol>


    <h2>June 23 2012</h2>


    <ol>
      <li>Rename title to "Media Capture and Streams".</li>


      <li>Update document to comply with HTML5.</li>


      <li>Update image describing a MediaStream.</li>


      <li>Add known issues and various other editorial changes.</li>
    </ol>


    <h2>June 22 2012</h2>


    <ol>
      <li>Update wording for constraints algorithm.</li>
    </ol>


    <h2>June 19 2012</h2>


    <ol>
      <li>Added "Media Streams as Media Elements section".</li>
    </ol>


    <h2>June 12 2012</h2>


    <ol>
      <li>Switch to respec v3.</li>
    </ol>


    <h2>June 5 2012</h2>


    <ol>
      <li>Added non-normative section "Implementation Suggestions".</li>


      <li>Removed stray whitespace.</li>
    </ol>


    <h2>June 1 2012</h2>


    <ol>
      <li>Added media constraint algorithm.</li>
    </ol>


    <h2>Apr 23 2012</h2>


    <ol>
      <li>Remove MediaStreamRecorder.</li>
    </ol>


    <h2>Apr 20 2012</h2>


    <ol>
      <li>Add definitions of MediaStreams and related objects.</li>
    </ol>


    <h2>Dec 21 2011</h2>


    <ol>
      <li>Changed to make wanted media opt in (rather than opt out). Minor
      edits.</li>
    </ol>


    <h2>Nov 29 2011</h2>


    <ol>
      <li>Changed examples to use MediaStreamOptions objects rather than
      strings. Minor edits.</li>
    </ol>


    <h2>Nov 15 2011</h2>


    <ol>
      <li>Removed MediaStream stuff. Refers to webrtc 1.0 spec for that part
      instead.</li>
    </ol>


    <h2>Nov 9 2011</h2>


    <ol>
      <li>Created first version by copying the webrtc spec and ripping out
      stuff. Put it on github.</li>
    </ol>
  </section>
    

  <section class="appendix">
    <h2>Acknowledgements</h2>

    <p>The editors wish to thank the Working Group chairs and Team Contact,
    Harald Alvestrand, Stefan Håkansson and Dominique Hazaël-Massieux, for
    their support. Substantial text in this specification was provided by many
    people including 
    <!-- tag 1 to reduce merge conflicts when adding names to list  -->
     Jim Barnett, <!-- tag 2 -->
     Harald Alvestrand, <!-- tag 3 -->
     <!-- tag 4 -->
     <!-- tag 5 -->
     <!-- tag 6 -->
     <!-- tag 7 -->
     <!-- tag 8 -->
     <!-- tag 9 -->
     and Stefan Håkansson.</p>
        
  </section>
</body>
</html>
